[
  {
    "objectID": "docs/getting_started/index.html",
    "href": "docs/getting_started/index.html",
    "title": "Getting Started",
    "section": "",
    "text": "This package works with python 3.9, 3.10 and 3.11.\nWe recommend running the package with a virtual environment such as conda or venv.\nWith conda:\nconda create -n assess-gtfs python=3.11 -y\nOnce completed, activate the environment:\nconda activate assess-gtfs\nInstall the python package with required dependencies:\npip install assess-gtfs\nTo use assess-gtfs, you will need a source of GTFS data. To locate your own, follow the how-to on GTFS data.\nAlternatively, you can use the small GTFS fixture that is bundled with the assess_gtfs package.\n\nimport glob\nimport os\n\nfrom assess_gtfs.multi_validation import MultiGtfsInstance\nfrom assess_gtfs.utils.constants import PKG_PATH # to access package data\n\ngtfs_pth = os.path.join(PKG_PATH, \"data\")\ngtfs = MultiGtfsInstance(glob.glob(gtfs_pth + \"/*.zip\"))\ngtfs.is_valid()\n\n  0%|          | 0/1 [00:00&lt;?, ?it/s]Validating GTFS from path /opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/data/newport-20230613_gtfs.zip:   0%|          | 0/1 [00:00&lt;?, ?it/s]Validating GTFS from path /opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/data/newport-20230613_gtfs.zip: 100%|██████████| 1/1 [00:00&lt;00:00,  7.07it/s]Validating GTFS from path /opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/data/newport-20230613_gtfs.zip: 100%|██████████| 1/1 [00:00&lt;00:00,  7.04it/s]\n\n\n\n\n\n\n\n\n\ntype\nmessage\ntable\nrows\nGTFS\n\n\n\n\n0\nerror\nInvalid route_type; maybe has extra space char...\nroutes\n[1, 2, 3, 4]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n1\nwarning\nUnrecognized column agency_noc\nagency\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n2\nwarning\nFeed expired\ncalendar\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n3\nwarning\nRepeated pair (route_short_name, route_long_name)\nroutes\n[13]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n4\nwarning\nUnrecognized column stop_direction_name\nstop_times\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n5\nwarning\nUnrecognized column platform_code\nstops\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n6\nwarning\nUnrecognized column trip_direction_name\ntrips\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n7\nwarning\nUnrecognized column vehicle_journey_code\ntrips\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n\n\n\n\n\nFor more on how to use assess-gtfs, see the tutorial."
  },
  {
    "objectID": "docs/getting_started/index.html#usage",
    "href": "docs/getting_started/index.html#usage",
    "title": "Getting Started",
    "section": "",
    "text": "This package works with python 3.9, 3.10 and 3.11.\nWe recommend running the package with a virtual environment such as conda or venv.\nWith conda:\nconda create -n assess-gtfs python=3.11 -y\nOnce completed, activate the environment:\nconda activate assess-gtfs\nInstall the python package with required dependencies:\npip install assess-gtfs\nTo use assess-gtfs, you will need a source of GTFS data. To locate your own, follow the how-to on GTFS data.\nAlternatively, you can use the small GTFS fixture that is bundled with the assess_gtfs package.\n\nimport glob\nimport os\n\nfrom assess_gtfs.multi_validation import MultiGtfsInstance\nfrom assess_gtfs.utils.constants import PKG_PATH # to access package data\n\ngtfs_pth = os.path.join(PKG_PATH, \"data\")\ngtfs = MultiGtfsInstance(glob.glob(gtfs_pth + \"/*.zip\"))\ngtfs.is_valid()\n\n  0%|          | 0/1 [00:00&lt;?, ?it/s]Validating GTFS from path /opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/data/newport-20230613_gtfs.zip:   0%|          | 0/1 [00:00&lt;?, ?it/s]Validating GTFS from path /opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/data/newport-20230613_gtfs.zip: 100%|██████████| 1/1 [00:00&lt;00:00,  7.07it/s]Validating GTFS from path /opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/data/newport-20230613_gtfs.zip: 100%|██████████| 1/1 [00:00&lt;00:00,  7.04it/s]\n\n\n\n\n\n\n\n\n\ntype\nmessage\ntable\nrows\nGTFS\n\n\n\n\n0\nerror\nInvalid route_type; maybe has extra space char...\nroutes\n[1, 2, 3, 4]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n1\nwarning\nUnrecognized column agency_noc\nagency\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n2\nwarning\nFeed expired\ncalendar\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n3\nwarning\nRepeated pair (route_short_name, route_long_name)\nroutes\n[13]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n4\nwarning\nUnrecognized column stop_direction_name\nstop_times\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n5\nwarning\nUnrecognized column platform_code\nstops\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n6\nwarning\nUnrecognized column trip_direction_name\ntrips\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n7\nwarning\nUnrecognized column vehicle_journey_code\ntrips\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n\n\n\n\n\nFor more on how to use assess-gtfs, see the tutorial."
  },
  {
    "objectID": "docs/how_to/index.html",
    "href": "docs/how_to/index.html",
    "title": "Get Public Transit Schedule Data (GTFS)",
    "section": "",
    "text": "These pages are short step-by-step instructions on how-to get something done, in particular retrieve the required input data for assess-gtfs.\nRegardless of the source of GTFS, assess-gtfs expects feeds to be compressed zip archives.\nassess-gtfs was written to prepare GTFS feeds for a comparison of British & French urban transport performance. This guide covers ingesting data from those territories. For other global territory data, consult the GTFS data index.\nWe recommend keeping your feed in your project directory under “data/external”. If you are using git version control, ensure that this directory is git-ignored."
  },
  {
    "objectID": "docs/how_to/index.html#british-gtfs",
    "href": "docs/how_to/index.html#british-gtfs",
    "title": "Get Public Transit Schedule Data (GTFS)",
    "section": "British GTFS",
    "text": "British GTFS\n\nBus\n\nAccess the Bus Open Data Service\nClick on “Timetables data”\nCreate an account (if needed)\nNavigate to “Download regional and national data sets in GTFS format”\nSelect the region of interest and click the link to download the file.\n\n\n\nRail\n\nAccess National Rail Data Portal\nCreate or register for an account (if needed)\nAccess the GB timetable GTFS from the daily feed section"
  },
  {
    "objectID": "docs/how_to/index.html#french-gtfs",
    "href": "docs/how_to/index.html#french-gtfs",
    "title": "Get Public Transit Schedule Data (GTFS)",
    "section": "French GTFS",
    "text": "French GTFS\n\nVisit transport.data.gouv.fr for bus and rail GTFS\nSearch for the region of France that you wish to acquire GTFS for.\nAlternatively, you can browse the available data by map, table or read the API documentation under the section “You can also”.\nOnce you have selected an entry, ensure that it is tagged as “gtfs”, but not “gtfs-r”, which stands for “realtime”.\nMake note of the indicated transit modality and click “Download” to save the zip archive to disk.\nOptionally, use the site’s validation tool to check the quality of a file or feed."
  },
  {
    "objectID": "docs/reference/cleaners.html",
    "href": "docs/reference/cleaners.html",
    "title": "cleaners",
    "section": "",
    "text": "cleaners\nA set of functions that clean the gtfs data.\n\n\n\n\n\nName\nDescription\n\n\n\n\nclean_consecutive_stop_fast_travel_warnings\nClean ‘Fast Travel Between Consecutive Stops’ warnings from validity_df.\n\n\nclean_multiple_stop_fast_travel_warnings\nClean ‘Fast Travel Over Multiple Stops’ warnings from validity_df.\n\n\ndrop_trips\nDrop trip(s) from a GtfsInstance object.\n\n\n\n\n\ncleaners.clean_consecutive_stop_fast_travel_warnings(gtfs, validate=False)\nClean ‘Fast Travel Between Consecutive Stops’ warnings from validity_df.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GtfsInstance to clean warnings within\nrequired\n\n\nvalidate\nbool\nWhether or not to validate the gtfs before carrying out this cleaning operation\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\ncleaners.clean_multiple_stop_fast_travel_warnings(gtfs, validate=False)\nClean ‘Fast Travel Over Multiple Stops’ warnings from validity_df.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GtfsInstance to clean warnings within\nrequired\n\n\nvalidate\nbool\nWhether or not to validate the gtfs before carrying out this cleaning operation\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\ncleaners.drop_trips(gtfs, trip_id)\nDrop trip(s) from a GtfsInstance object.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GtfsInstance object to drop the trip(s) from\nrequired\n\n\ntrip_id\nUnion[str, list, np.ndarray]\nThe trip ID(s) of the trip to be dropped from the gtfs data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "cleaners"
    ]
  },
  {
    "objectID": "docs/reference/cleaners.html#functions",
    "href": "docs/reference/cleaners.html#functions",
    "title": "cleaners",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nclean_consecutive_stop_fast_travel_warnings\nClean ‘Fast Travel Between Consecutive Stops’ warnings from validity_df.\n\n\nclean_multiple_stop_fast_travel_warnings\nClean ‘Fast Travel Over Multiple Stops’ warnings from validity_df.\n\n\ndrop_trips\nDrop trip(s) from a GtfsInstance object.\n\n\n\n\n\ncleaners.clean_consecutive_stop_fast_travel_warnings(gtfs, validate=False)\nClean ‘Fast Travel Between Consecutive Stops’ warnings from validity_df.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GtfsInstance to clean warnings within\nrequired\n\n\nvalidate\nbool\nWhether or not to validate the gtfs before carrying out this cleaning operation\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\ncleaners.clean_multiple_stop_fast_travel_warnings(gtfs, validate=False)\nClean ‘Fast Travel Over Multiple Stops’ warnings from validity_df.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GtfsInstance to clean warnings within\nrequired\n\n\nvalidate\nbool\nWhether or not to validate the gtfs before carrying out this cleaning operation\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\ncleaners.drop_trips(gtfs, trip_id)\nDrop trip(s) from a GtfsInstance object.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GtfsInstance object to drop the trip(s) from\nrequired\n\n\ntrip_id\nUnion[str, list, np.ndarray]\nThe trip ID(s) of the trip to be dropped from the gtfs data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "cleaners"
    ]
  },
  {
    "objectID": "docs/reference/index.html",
    "href": "docs/reference/index.html",
    "title": "API reference",
    "section": "",
    "text": "Modules for working with GTFS public transit schedule files.\n\n\n\ncalendar\nCleaners & utilities specific to the calendar table.\n\n\ncleaners\nA set of functions that clean the gtfs data.\n\n\ngtfs_utils\nUtility functions for GTFS archives.\n\n\nmulti_validation\nValidating multiple GTFS at once.\n\n\nroutes\nHelpers for working with routes.txt.\n\n\nvalidation\nValidating GTFS data.\n\n\nvalidators\nA set of functions that validate the GTFS data.\n\n\n\n\n\n\nModules to handle common package utility functions.\n\n\n\ndefence\nDefensive check utility funcs. Internals only.\n\n\nio\nHelper functions to handle IO operations.",
    "crumbs": [
      "API Reference",
      "API reference"
    ]
  },
  {
    "objectID": "docs/reference/index.html#gtfs",
    "href": "docs/reference/index.html#gtfs",
    "title": "API reference",
    "section": "",
    "text": "Modules for working with GTFS public transit schedule files.\n\n\n\ncalendar\nCleaners & utilities specific to the calendar table.\n\n\ncleaners\nA set of functions that clean the gtfs data.\n\n\ngtfs_utils\nUtility functions for GTFS archives.\n\n\nmulti_validation\nValidating multiple GTFS at once.\n\n\nroutes\nHelpers for working with routes.txt.\n\n\nvalidation\nValidating GTFS data.\n\n\nvalidators\nA set of functions that validate the GTFS data.",
    "crumbs": [
      "API Reference",
      "API reference"
    ]
  },
  {
    "objectID": "docs/reference/index.html#utils",
    "href": "docs/reference/index.html#utils",
    "title": "API reference",
    "section": "",
    "text": "Modules to handle common package utility functions.\n\n\n\ndefence\nDefensive check utility funcs. Internals only.\n\n\nio\nHelper functions to handle IO operations.",
    "crumbs": [
      "API Reference",
      "API reference"
    ]
  },
  {
    "objectID": "docs/reference/validators.html",
    "href": "docs/reference/validators.html",
    "title": "validators",
    "section": "",
    "text": "validators\nA set of functions that validate the GTFS data.\n\n\n\n\n\nName\nDescription\n\n\n\n\nvalidate_travel_between_consecutive_stops\nValidate the travel between consecutive stops in the GTFS data.\n\n\nvalidate_travel_over_multiple_stops\nValidate travel over multiple stops in the GTFS data.\n\n\n\n\n\nvalidators.validate_travel_between_consecutive_stops(gtfs)\nValidate the travel between consecutive stops in the GTFS data.\nEnsures that a trip is valid by examining the duration and distance of a trip. If a vehicle is travelling at an unusual speed, the trip can be deemed invalid.\n\n\n\nvalidators.validate_travel_over_multiple_stops(gtfs)\nValidate travel over multiple stops in the GTFS data.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "validators"
    ]
  },
  {
    "objectID": "docs/reference/validators.html#functions",
    "href": "docs/reference/validators.html#functions",
    "title": "validators",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nvalidate_travel_between_consecutive_stops\nValidate the travel between consecutive stops in the GTFS data.\n\n\nvalidate_travel_over_multiple_stops\nValidate travel over multiple stops in the GTFS data.\n\n\n\n\n\nvalidators.validate_travel_between_consecutive_stops(gtfs)\nValidate the travel between consecutive stops in the GTFS data.\nEnsures that a trip is valid by examining the duration and distance of a trip. If a vehicle is travelling at an unusual speed, the trip can be deemed invalid.\n\n\n\nvalidators.validate_travel_over_multiple_stops(gtfs)\nValidate travel over multiple stops in the GTFS data.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "validators"
    ]
  },
  {
    "objectID": "docs/reference/io.html",
    "href": "docs/reference/io.html",
    "title": "io",
    "section": "",
    "text": "utils.io\nHelper functions to handle IO operations.\n\n\n\n\n\nName\nDescription\n\n\n\n\nfrom_pickle\nRead a pickled object from file.\n\n\nto_pickle\nPickle an object for later reuse.\n\n\n\n\n\nutils.io.from_pickle(path)\nRead a pickled object from file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, pathlib.Path]\nPath of saved pickle file.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nObject in pickle file. Must have a “.pkl” or “.pickle” file extension.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\npath is not a string or a pathlib.Path type.\n\n\nFileNotFoundError\npath does not exist\n\n\nValueError\npath does not have either a “.pkl” or “.pickle” file extension.\n\n\n\n\n\n\n\nutils.io.to_pickle(picklable_object, path)\nPickle an object for later reuse.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npicklable_object\nAny\nObject to be saved to pickle file. If the directory does not exist one will be generated.\nrequired\n\n\npath\nUnion[str, pathlib.Path]\nPath to save pickle file. Must have a “.pkl” or “.pickle” file extension or it will be coerced to “.pkl”.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nUserWarning\nWhen path does not have a “.pkl” or “.pickle” file extension. The warning will signify for coercion to a path with the “.pkl” extension.",
    "crumbs": [
      "API Reference",
      "`utils`",
      "io"
    ]
  },
  {
    "objectID": "docs/reference/io.html#functions",
    "href": "docs/reference/io.html#functions",
    "title": "io",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nfrom_pickle\nRead a pickled object from file.\n\n\nto_pickle\nPickle an object for later reuse.\n\n\n\n\n\nutils.io.from_pickle(path)\nRead a pickled object from file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, pathlib.Path]\nPath of saved pickle file.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nObject in pickle file. Must have a “.pkl” or “.pickle” file extension.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\npath is not a string or a pathlib.Path type.\n\n\nFileNotFoundError\npath does not exist\n\n\nValueError\npath does not have either a “.pkl” or “.pickle” file extension.\n\n\n\n\n\n\n\nutils.io.to_pickle(picklable_object, path)\nPickle an object for later reuse.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npicklable_object\nAny\nObject to be saved to pickle file. If the directory does not exist one will be generated.\nrequired\n\n\npath\nUnion[str, pathlib.Path]\nPath to save pickle file. Must have a “.pkl” or “.pickle” file extension or it will be coerced to “.pkl”.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nUserWarning\nWhen path does not have a “.pkl” or “.pickle” file extension. The warning will signify for coercion to a path with the “.pkl” extension.",
    "crumbs": [
      "API Reference",
      "`utils`",
      "io"
    ]
  },
  {
    "objectID": "docs/reference/multi_validation.html",
    "href": "docs/reference/multi_validation.html",
    "title": "multi_validation",
    "section": "",
    "text": "multi_validation\nValidating multiple GTFS at once.\n\n\n\n\n\nName\nDescription\n\n\n\n\nMultiGtfsInstance\nCreate a feed instance for multiple GTFS files.\n\n\n\n\n\nmulti_validation.MultiGtfsInstance(self, path)\nCreate a feed instance for multiple GTFS files.\nThis allows for multiple GTFS files to be cleaned, validated, summarised, filtered and saved at the same time.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, list, pathlib.Path]\nA list of paths, a singular path object, or a glob string. See more information on glob strings here: https://docs.python.org/3/library/glob.html\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\npaths\nlist\nA list of the GTFS paths used to create the MultiGtfsInstance object.\n\n\ninstances\nlist\nA list of GtfsInstance objects created from self.paths.\n\n\ndaily_trip_summary\npd.DataFrame\nA combined summary of statistics for trips from all GTFS files in the MultiGtfsInstance.\n\n\ndaily_route_summary\npd.DataFrame\nA combined summary of statistics for routes from all GTFS files in the MultiGtfsInstance.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n‘path’ is not of type string or list.\n\n\nFileNotFoundError\nOne (or more) of the paths passed to ‘path’ does not exist.\n\n\nFileNotFoundError\nThere are no GTFS files found in the passed list of paths, or from the glob string.\n\n\nValueError\nPath has no file extension.\n\n\nValueError\nOne (or more) of the paths passed are not of the filetype ‘.zip’.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nclean_feeds\nClean each of the feeds in the MultiGtfsInstance.\n\n\nensure_populated_calendars\nCheck if calendar is absent and creates one from calendar_dates.\n\n\nfilter_to_bbox\nFilter GTFS to a bbox.\n\n\nfilter_to_date\nFilter each GTFS to date(s).\n\n\nget_dates\nGet all available dates from calendar.txt (or calendar_dates.txt).\n\n\nis_valid\nValidate each of the feeds in the MultiGtfsInstance.\n\n\nplot_service\nCreate a line plot of route or trip counts over time.\n\n\nsave_feeds\nSave the GtfsInstances to a directory.\n\n\nsummarise_routes\nSummarise the combined GTFS data by route_id.\n\n\nsummarise_trips\nSummarise the combined GTFS data by trip_id.\n\n\nvalidate_empty_feeds\nEnsure the feeds in MultiGtfsInstance are not empty.\n\n\nviz_stops\nVisualise all stops from all of the GTFS files.\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.clean_feeds(clean_kwargs=None)\nClean each of the feeds in the MultiGtfsInstance.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nclean_kwargs\nUnion[dict, None]\nThe kwargs to pass to GtfsInstance.clean_feed() for each Gtfs in the MultiGtfsInstance, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.ensure_populated_calendars()\nCheck if calendar is absent and creates one from calendar_dates.\nShallow wrapper around GtfsInstance.ensure_populated_calendar().\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.filter_to_bbox(bbox, crs='epsg:4326', delete_empty_feeds=False)\nFilter GTFS to a bbox.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbbox\nUnion[list, GeoDataFrame]\nThe bbox to filter the GTFS to. Leave as none if the GTFS does not need to be cropped. Format - [xmin, ymin, xmax, ymax]\nrequired\n\n\ncrs\nUnion[str, int]\nThe CRS of the given bbox, by default “epsg:4326”\n'epsg:4326'\n\n\ndelete_empty_feeds\nbool\nWhether or not to remove empty feeds, by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.filter_to_date(dates, delete_empty_feeds=False)\nFilter each GTFS to date(s).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndates\nUnion[str, list]\nThe date(s) to filter the GTFS to\nrequired\n\n\ndelete_empty_feeds\nbool\nWhether or not to remove empty feeds, by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.get_dates(return_range=True)\nGet all available dates from calendar.txt (or calendar_dates.txt).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nreturn_range\nbool\nWhether to return the raw dates, or the min/max range, by default True\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nEither the full set of dates, or the range that the dates span between\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.is_valid(validation_kwargs=None)\nValidate each of the feeds in the MultiGtfsInstance.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalidation_kwargs\nUnion[dict, None]\nThe kwargs to pass to GtfsInstance.is_valid() for each Gtfs in the MultiGtfsInstance, by default None\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nself.validity_df : pd.DataFrame\nA dataframe containing the validation messages from all of the GtfsInstances.\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.plot_service(service_type='routes', route_type=True, width=1000, height=550, title=None, plotly_kwargs=None, rolling_average=None, line_date=None)\nCreate a line plot of route or trip counts over time.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nservice_type\nstr\nWhether to plot ‘routes’ or ‘trips’. By default ‘routes’.\n'routes'\n\n\nroute_type\nbool\nWhether or not to draw a line for each modality, by default True\nTrue\n\n\nwidth\nint\nPlot width, by default 1000\n1000\n\n\nheight\nint\nPlot height, by default 550\n550\n\n\ntitle\nstr\nPlot title, by default None\nNone\n\n\nplotly_kwargs\ndict\nKwargs to pass to plotly.express.line, by default None\nNone\n\n\nrolling_average\nUnion[int, None]\nHow many days to calculate the rolling average over. When left as None, rolling average is not used. The rolling average is calculated from the centre, meaning if ra=3, the average will be calculated from the current date, previous date and following date. Missing dates are imputed and treated as having values of 0.\nNone\n\n\nline_date\nUnion[str, None]\nA date to draw a dashed vertical line on. Date should be in format: YYYY-MM-DD, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ngo.Figure\nThe timerseries plot\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.save_feeds(dir, suffix='_new', file_names=None, overwrite=False)\nSave the GtfsInstances to a directory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndir\nUnion[pathlib.Path, str]\nThe directory to export the GTFS files into.\nrequired\n\n\nsuffix\nstr\nThe suffix to apply to save names. The ‘file_name’ param takes priority here.\n'_new'\n\n\nfile_names\nlist\nA list of save names for the altered GTFS. The list must be the same length as the number of GTFS instances. Takes priority over the ‘suffix’ param. Names will be used in order of the instances (access using self.instances()).\nNone\n\n\noverwrite\nbool\nWhether or not to overwrite the pre-existing saves with matching paths.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.summarise_routes(summ_ops=[np.min, np.max, np.mean, np.median], return_summary=True, to_days=False, sort_by_route_type=False)\nSummarise the combined GTFS data by route_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsumm_ops\nlist\nA list of numpy operators to gather a summary on. Accepts operators (e.g., np.min) or strings (“min”), by default [np.min, np.max, np.mean, np.median].\n[np.min, np.max, np.mean, np.median]\n\n\nreturn_summary\nbool\nWhen set to False, full data for each trip on each date will be returned, by default True.\nTrue\n\n\nto_days\nbool\nWhether or not to aggregate to days, or to just return counts for trips/routes for each date. When False, summ_ops becomes useless, and should therefore nothing should be passed when calling this function (so it remains as the default), by default False.\nFalse\n\n\nsort_by_route_type\nbool\nWhether or not to sort the resulting dataframe by route_type. This only impacts the resulting df when to_days=True, by default False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA dataframe containing the summary\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.summarise_trips(summ_ops=[np.min, np.max, np.mean, np.median], return_summary=True, to_days=False, sort_by_route_type=False)\nSummarise the combined GTFS data by trip_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsumm_ops\nlist\nA list of numpy operators to summarise with. Accepts operators (e.g., np.min) or strings (“min”) ,by default [np.min, np.max, np.mean, np.median]\n[np.min, np.max, np.mean, np.median]\n\n\nreturn_summary\nbool\nWhen set to False, full data for each trip on each date will be returned, by default True.\nTrue\n\n\nto_days\nbool\nWhether or not to aggregate to days, or to just return counts for trips/routes for each date. When False, summ_ops becomes useless, and therefore nothing should be passed when calling this function (so it remains as the default), by default False.\nFalse\n\n\nsort_by_route_type\nbool\nWhether or not to sort the resulting dataframe by route_type. This only impacts the resulting df when to_days=True, by default False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA dataframe containing the summary\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.validate_empty_feeds(delete=False)\nEnsure the feeds in MultiGtfsInstance are not empty.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndelete\nbool\nWhether or not to delete the empty feeds, by default False\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nA list of feeds that are empty and their index in MultiGtfsInstance.instances\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.viz_stops(path=None, return_viz=True, filtered_only=True)\nVisualise all stops from all of the GTFS files.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, pathlib.Path]\nThe path to save the folium map to, by default None.\nNone\n\n\nreturn_viz\nbool\nWhether or not to return the folium map object, by default True.\nTrue\n\n\nfiltered_only\nbool\nWhether to filter the stops that are plotted to only stop_id’s that are present in the stop_times table, by default True.\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nfolium.Map\nA folium map with all stops plotted on it.\n\n\nNone\nReturns none if ‘return_viz’ is False.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nAn error is raised if both path and return_viz parameters are None as the map won’t be saved or returned.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "multi_validation"
    ]
  },
  {
    "objectID": "docs/reference/multi_validation.html#classes",
    "href": "docs/reference/multi_validation.html#classes",
    "title": "multi_validation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nMultiGtfsInstance\nCreate a feed instance for multiple GTFS files.\n\n\n\n\n\nmulti_validation.MultiGtfsInstance(self, path)\nCreate a feed instance for multiple GTFS files.\nThis allows for multiple GTFS files to be cleaned, validated, summarised, filtered and saved at the same time.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, list, pathlib.Path]\nA list of paths, a singular path object, or a glob string. See more information on glob strings here: https://docs.python.org/3/library/glob.html\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\npaths\nlist\nA list of the GTFS paths used to create the MultiGtfsInstance object.\n\n\ninstances\nlist\nA list of GtfsInstance objects created from self.paths.\n\n\ndaily_trip_summary\npd.DataFrame\nA combined summary of statistics for trips from all GTFS files in the MultiGtfsInstance.\n\n\ndaily_route_summary\npd.DataFrame\nA combined summary of statistics for routes from all GTFS files in the MultiGtfsInstance.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n‘path’ is not of type string or list.\n\n\nFileNotFoundError\nOne (or more) of the paths passed to ‘path’ does not exist.\n\n\nFileNotFoundError\nThere are no GTFS files found in the passed list of paths, or from the glob string.\n\n\nValueError\nPath has no file extension.\n\n\nValueError\nOne (or more) of the paths passed are not of the filetype ‘.zip’.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nclean_feeds\nClean each of the feeds in the MultiGtfsInstance.\n\n\nensure_populated_calendars\nCheck if calendar is absent and creates one from calendar_dates.\n\n\nfilter_to_bbox\nFilter GTFS to a bbox.\n\n\nfilter_to_date\nFilter each GTFS to date(s).\n\n\nget_dates\nGet all available dates from calendar.txt (or calendar_dates.txt).\n\n\nis_valid\nValidate each of the feeds in the MultiGtfsInstance.\n\n\nplot_service\nCreate a line plot of route or trip counts over time.\n\n\nsave_feeds\nSave the GtfsInstances to a directory.\n\n\nsummarise_routes\nSummarise the combined GTFS data by route_id.\n\n\nsummarise_trips\nSummarise the combined GTFS data by trip_id.\n\n\nvalidate_empty_feeds\nEnsure the feeds in MultiGtfsInstance are not empty.\n\n\nviz_stops\nVisualise all stops from all of the GTFS files.\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.clean_feeds(clean_kwargs=None)\nClean each of the feeds in the MultiGtfsInstance.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nclean_kwargs\nUnion[dict, None]\nThe kwargs to pass to GtfsInstance.clean_feed() for each Gtfs in the MultiGtfsInstance, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.ensure_populated_calendars()\nCheck if calendar is absent and creates one from calendar_dates.\nShallow wrapper around GtfsInstance.ensure_populated_calendar().\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.filter_to_bbox(bbox, crs='epsg:4326', delete_empty_feeds=False)\nFilter GTFS to a bbox.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbbox\nUnion[list, GeoDataFrame]\nThe bbox to filter the GTFS to. Leave as none if the GTFS does not need to be cropped. Format - [xmin, ymin, xmax, ymax]\nrequired\n\n\ncrs\nUnion[str, int]\nThe CRS of the given bbox, by default “epsg:4326”\n'epsg:4326'\n\n\ndelete_empty_feeds\nbool\nWhether or not to remove empty feeds, by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.filter_to_date(dates, delete_empty_feeds=False)\nFilter each GTFS to date(s).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndates\nUnion[str, list]\nThe date(s) to filter the GTFS to\nrequired\n\n\ndelete_empty_feeds\nbool\nWhether or not to remove empty feeds, by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.get_dates(return_range=True)\nGet all available dates from calendar.txt (or calendar_dates.txt).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nreturn_range\nbool\nWhether to return the raw dates, or the min/max range, by default True\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nEither the full set of dates, or the range that the dates span between\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.is_valid(validation_kwargs=None)\nValidate each of the feeds in the MultiGtfsInstance.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalidation_kwargs\nUnion[dict, None]\nThe kwargs to pass to GtfsInstance.is_valid() for each Gtfs in the MultiGtfsInstance, by default None\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nself.validity_df : pd.DataFrame\nA dataframe containing the validation messages from all of the GtfsInstances.\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.plot_service(service_type='routes', route_type=True, width=1000, height=550, title=None, plotly_kwargs=None, rolling_average=None, line_date=None)\nCreate a line plot of route or trip counts over time.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nservice_type\nstr\nWhether to plot ‘routes’ or ‘trips’. By default ‘routes’.\n'routes'\n\n\nroute_type\nbool\nWhether or not to draw a line for each modality, by default True\nTrue\n\n\nwidth\nint\nPlot width, by default 1000\n1000\n\n\nheight\nint\nPlot height, by default 550\n550\n\n\ntitle\nstr\nPlot title, by default None\nNone\n\n\nplotly_kwargs\ndict\nKwargs to pass to plotly.express.line, by default None\nNone\n\n\nrolling_average\nUnion[int, None]\nHow many days to calculate the rolling average over. When left as None, rolling average is not used. The rolling average is calculated from the centre, meaning if ra=3, the average will be calculated from the current date, previous date and following date. Missing dates are imputed and treated as having values of 0.\nNone\n\n\nline_date\nUnion[str, None]\nA date to draw a dashed vertical line on. Date should be in format: YYYY-MM-DD, by default None\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ngo.Figure\nThe timerseries plot\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.save_feeds(dir, suffix='_new', file_names=None, overwrite=False)\nSave the GtfsInstances to a directory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndir\nUnion[pathlib.Path, str]\nThe directory to export the GTFS files into.\nrequired\n\n\nsuffix\nstr\nThe suffix to apply to save names. The ‘file_name’ param takes priority here.\n'_new'\n\n\nfile_names\nlist\nA list of save names for the altered GTFS. The list must be the same length as the number of GTFS instances. Takes priority over the ‘suffix’ param. Names will be used in order of the instances (access using self.instances()).\nNone\n\n\noverwrite\nbool\nWhether or not to overwrite the pre-existing saves with matching paths.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.summarise_routes(summ_ops=[np.min, np.max, np.mean, np.median], return_summary=True, to_days=False, sort_by_route_type=False)\nSummarise the combined GTFS data by route_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsumm_ops\nlist\nA list of numpy operators to gather a summary on. Accepts operators (e.g., np.min) or strings (“min”), by default [np.min, np.max, np.mean, np.median].\n[np.min, np.max, np.mean, np.median]\n\n\nreturn_summary\nbool\nWhen set to False, full data for each trip on each date will be returned, by default True.\nTrue\n\n\nto_days\nbool\nWhether or not to aggregate to days, or to just return counts for trips/routes for each date. When False, summ_ops becomes useless, and should therefore nothing should be passed when calling this function (so it remains as the default), by default False.\nFalse\n\n\nsort_by_route_type\nbool\nWhether or not to sort the resulting dataframe by route_type. This only impacts the resulting df when to_days=True, by default False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA dataframe containing the summary\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.summarise_trips(summ_ops=[np.min, np.max, np.mean, np.median], return_summary=True, to_days=False, sort_by_route_type=False)\nSummarise the combined GTFS data by trip_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsumm_ops\nlist\nA list of numpy operators to summarise with. Accepts operators (e.g., np.min) or strings (“min”) ,by default [np.min, np.max, np.mean, np.median]\n[np.min, np.max, np.mean, np.median]\n\n\nreturn_summary\nbool\nWhen set to False, full data for each trip on each date will be returned, by default True.\nTrue\n\n\nto_days\nbool\nWhether or not to aggregate to days, or to just return counts for trips/routes for each date. When False, summ_ops becomes useless, and therefore nothing should be passed when calling this function (so it remains as the default), by default False.\nFalse\n\n\nsort_by_route_type\nbool\nWhether or not to sort the resulting dataframe by route_type. This only impacts the resulting df when to_days=True, by default False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA dataframe containing the summary\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.validate_empty_feeds(delete=False)\nEnsure the feeds in MultiGtfsInstance are not empty.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndelete\nbool\nWhether or not to delete the empty feeds, by default False\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nA list of feeds that are empty and their index in MultiGtfsInstance.instances\n\n\n\n\n\n\n\nmulti_validation.MultiGtfsInstance.viz_stops(path=None, return_viz=True, filtered_only=True)\nVisualise all stops from all of the GTFS files.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, pathlib.Path]\nThe path to save the folium map to, by default None.\nNone\n\n\nreturn_viz\nbool\nWhether or not to return the folium map object, by default True.\nTrue\n\n\nfiltered_only\nbool\nWhether to filter the stops that are plotted to only stop_id’s that are present in the stop_times table, by default True.\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nfolium.Map\nA folium map with all stops plotted on it.\n\n\nNone\nReturns none if ‘return_viz’ is False.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nAn error is raised if both path and return_viz parameters are None as the map won’t be saved or returned.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "multi_validation"
    ]
  },
  {
    "objectID": "index.html#what-is-assess-gtfs",
    "href": "index.html#what-is-assess-gtfs",
    "title": "assess-gtfs documentation",
    "section": "What is assess-gtfs?",
    "text": "What is assess-gtfs?\nGeneral Transit Feed Specification (GTFS) is a common data format for public transit information. GTFS is a prerequisite for undertaking routing with public transit schedules.\nThe assess-gtfs Python package helps to reduce barriers to understanding the service distribution within GTFS. More specifically, it enables developers to inspect, clean and process GTFS for more efficient, localised routing analysis.\n\nThe History of assess-gtfs\nassess-gtfs started out life as a module in the ONS Data Science Campus’ transport_performance package. assess-gtfs is built upon and inspired by the excellent gtfs_kit package. assess-gtfs was needed to process and inspect GTFS data prior to building transport networks with the r5py package. Building valid transit networks with the output of our GTFS processing pipelines has been the primary user requirement during development."
  },
  {
    "objectID": "index.html#where-do-i-go-now",
    "href": "index.html#where-do-i-go-now",
    "title": "assess-gtfs documentation",
    "section": "Where do I go now?",
    "text": "Where do I go now?\nThese docs are structured in accordance with the Diátaxis framework:\n\n\n\n🏁\n\n\nWant to get up and running with assess-gtfs quickly?\n\nGetting Started\n\n\n\n🔎\n\n\nNeed more details on the methods/tools used within assess-gtfs?\n\nExplanation\n\n\n\n🧭\n\n\nLooking for guidance on how to get something done (e.g. find input data)?\n\nHow-To\n\n\n\n📝\n\n\nInterested in learning how to use assess-gtfs by examples?\n\nTutorial\n\n\n\n📖\n\n\nRequiring a technical reference covering the assess-gtfs API?\n\nAPI reference\n\n\n\n🛠️\n\n\nWant to contribute to the development of assess-gtfs?\n\nGitHub\n\n\n\n\n\n\n\n\nNotes on contributing…\n\n\n\nWe hope that the open source and public sector communities will collaborate and build on this package. You can find the assess-gtfs source code on GitHub."
  },
  {
    "objectID": "docs/explanation/index.html",
    "href": "docs/explanation/index.html",
    "title": "Explanation",
    "section": "",
    "text": "These explanation pages provide an understanding of the assess-gtfs package.\nassess-gtfs allows users to validate, clean, inspect and filter transit timetable data in the General Transit Feed Specification (GTFS) format."
  },
  {
    "objectID": "docs/explanation/index.html#what-is-gtfs",
    "href": "docs/explanation/index.html#what-is-gtfs",
    "title": "Explanation",
    "section": "What is GTFS?",
    "text": "What is GTFS?\nGTFS files are compressed zip archives of text files. Each text file containing information about routes, trips, calendar, stop locations and so on. Various transport modelling software are able to use these files as a relational database in order to undertake routing operations.\nBelow are the file contents of a small sample of UK GTFS.\n.../tests/data/chester-20230816-small_gtfs/\n├── agency.txt\n├── calendar.txt\n├── calendar_dates.txt\n├── feed_info.txt\n├── routes.txt\n├── shapes.txt\n├── stop_times.txt\n├── stops.txt\n└── trips.txt\n\n1 directory, 9 files"
  },
  {
    "objectID": "docs/explanation/index.html#working-with-gtfs",
    "href": "docs/explanation/index.html#working-with-gtfs",
    "title": "Explanation",
    "section": "Working with GTFS",
    "text": "Working with GTFS\nIf you would prefer a demonstration of assess-gtfs, please follow the tutorial.\n\nFiltering GTFS\nWhen undertaking routing operations with GTFS, you typically need to filter large feeds to an area of interest. This ensures that building a transport network with a package such as r5py is optimised. Feeds can be restricted based upon location with a bounding box. They can also be restricted to a date or list of dates within the feed calendar. For more on filtering GTFS, please see the assess-gtfs api docs.\n\n\nInspecting GTFS\nUndertaking routing analysis tends to happen at a specific location and time or time window. It is important to assess the service distribution over the available dates within the GTFS. GTFS tend to come with a range of calendar dates, but the service volume across those dates can be variable and dependent upon the publication frequency of the specific feed.\nThe objective is to ensure a selected time of analysis is representative of average service volume within the feed. For a guide to doing this with assess-gtfs, please see the tutorial section on summarising GTFS.\n\n\nValidating GTFS\nWhen working with GTFS from a range of sources, it is important to understand whether the feed you intend to use is compliant. Online tools like that available on the French government’s Transport Data Portal are excellent choices for manual validation of a small number of feeds.\nassess-gtfs produces tabular outputs for specification warnings and errors using gtfs_kit under the hood. Note that not all of these errors are as severe as they initially appear. For example, the below validation table is commonly seen when validating British GTFS:\n\n\n\n\n\n\n\n\n\ntype\nmessage\ntable\nrows\nGTFS\n\n\n\n\n0\nerror\nInvalid route_type; maybe has extra space char...\nroutes\n[1, 2, 3, 4]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n1\nwarning\nUnrecognized column agency_noc\nagency\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n2\nwarning\nFeed expired\ncalendar\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n3\nwarning\nRepeated pair (route_short_name, route_long_name)\nroutes\n[13]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n4\nwarning\nUnrecognized column stop_direction_name\nstop_times\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n5\nwarning\nUnrecognized column platform_code\nstops\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n6\nwarning\nUnrecognized column trip_direction_name\ntrips\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n7\nwarning\nUnrecognized column vehicle_journey_code\ntrips\n[]\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/pyt...\n\n\n\n\n\n\n\nThe first row in the validity table shows an apparent error, reporting “Invalid route_type; maybe has extra space characters”. Examining the routes table for the affected rows:\n\n\n0      3\n1    200\n2    200\n3    200\n4    200\n5      3\n6      3\n7      3\n8      3\n9      3\nName: route_type, dtype: int64\n\n\nWe see that rows 1 through 4 use route_type 200. Google have proposed an extension to GTFS route_type that many publishers of GTFS have adopted. Here you can see that route_type 200 means a coach service and would not cause a problem for most routing software. For more on validating GTFS feeds, consult the api reference for implementation details.\n\n\nCleaning GTFS\nassess-gtfs can be used to attempt to resolve some of the identified problems in GTFS. To see how to do this, please follow along with the tutorial’s clean_feed section. Alternatively, visit the api documentation for more detail.\nNote that cleaning for all specification alerts has not been implemented. To raise a feature request with the package maintainers, please do so on GitHub."
  },
  {
    "objectID": "docs/reference/calendar.html",
    "href": "docs/reference/calendar.html",
    "title": "calendar",
    "section": "",
    "text": "calendar\nCleaners & utilities specific to the calendar table.\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_calendar_from_dates\nUse the calendar_dates table to populate a calendar table.\n\n\n\n\n\ncalendar.create_calendar_from_dates(calendar_dates)\nUse the calendar_dates table to populate a calendar table.\nUse this in cases where a gtfs feed has elected to use a calendar-dates table and no calendar. Only adds values for calendar_dates entries tagged as exception_type 1. Exception_type 2 is not treated. Those entries are ignored whilst making the calendar table.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncalendar_dates\npd.DataFrame\nThe calendar_dates table.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA calendar table based on values in the calendar_dates table.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\ncalendar_dates is not a pd.DataFrame\n\n\nIndexError\ncalendar_dates does not contain any of the following columns - service_id, date, exception_type.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "calendar"
    ]
  },
  {
    "objectID": "docs/reference/calendar.html#functions",
    "href": "docs/reference/calendar.html#functions",
    "title": "calendar",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_calendar_from_dates\nUse the calendar_dates table to populate a calendar table.\n\n\n\n\n\ncalendar.create_calendar_from_dates(calendar_dates)\nUse the calendar_dates table to populate a calendar table.\nUse this in cases where a gtfs feed has elected to use a calendar-dates table and no calendar. Only adds values for calendar_dates entries tagged as exception_type 1. Exception_type 2 is not treated. Those entries are ignored whilst making the calendar table.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncalendar_dates\npd.DataFrame\nThe calendar_dates table.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA calendar table based on values in the calendar_dates table.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\ncalendar_dates is not a pd.DataFrame\n\n\nIndexError\ncalendar_dates does not contain any of the following columns - service_id, date, exception_type.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "calendar"
    ]
  },
  {
    "objectID": "docs/reference/defence.html",
    "href": "docs/reference/defence.html",
    "title": "defence",
    "section": "",
    "text": "defence\nutils.defence\nDefensive check utility funcs. Internals only.",
    "crumbs": [
      "API Reference",
      "`utils`",
      "defence"
    ]
  },
  {
    "objectID": "docs/reference/validation.html",
    "href": "docs/reference/validation.html",
    "title": "validation",
    "section": "",
    "text": "validation\nValidating GTFS data.\n\n\n\n\n\nName\nDescription\n\n\n\n\nGtfsInstance\nCreate a feed instance for validation, cleaning & visualisation.\n\n\n\n\n\nvalidation.GtfsInstance(self, gtfs_pth, units='km', route_lookup_pth=None)\nCreate a feed instance for validation, cleaning & visualisation.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs_pth\nUnion[str, bytes, os.PathLike]\nFile path to GTFS archive.\nrequired\n\n\nunits\n(str, optionl)\nSpatial units of the GTFS file, defaults to “km”.\n'km'\n\n\nroute_lookup_pth\nUnion[str, pathlib.Path]\nThe path to the route type lookup. If left empty, the default path will be used. When None, route lookup table is read from file saved within this package, defaults to None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nfeed\ngtfs_kit.Feed\nA gtfs_kit feed produced using the files at gtfs_pth on init.\n\n\ngtfs_path\nUnion[str, pathlib.Path]\nThe path to the GTFS archive.\n\n\nfile_list\nlist\nFiles in the GTFS archive.\n\n\nvalidity_df\npd.DataFrame\nTable of GTFS errors, warnings & their descriptions.\n\n\ndated_trip_counts\npd.DataFrame\nDated trip counts by modality.\n\n\ndaily_trip_summary\npd.DataFrame\nSummarised trip results by day of the week and modality.\n\n\ndaily_route_summary\npd.DataFrame\nDated route counts by modality.\n\n\nroute_mode_summary_df\npd.DataFrame\nSummarised route counts by day of the week and modality.\n\n\npre_processed_trips\npd.DataFrame\nA table of pre-processed trip data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n1. pth is not either of string or pathlib.Path. 2. units is not of type str.\n\n\nFileExistsError\npth does not exist on disk.\n\n\nValueError\n1. pth does not have the expected file extension(s). 2. units are not one of: “m”, “km”, “metres”, “meters”, “kilometres”, “kilometers”.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nclean_feed\nAttempt to clean feed using gtfs_kit.\n\n\nensure_populated_calendar\nIf calendar is absent, creates one from calendar_dates.\n\n\nfilter_to_bbox\nVery shallow wrapper around filter_gfts().\n\n\nfilter_to_date\nVery shallow wrapper around filter_gtfs().\n\n\nget_gtfs_files\nReturn a list of files present in the GTFS feed.\n\n\nget_route_modes\nSummarise the available routes by their associated route_type.\n\n\nhtml_report\nGenerate a HTML report describing the GTFS data.\n\n\nis_valid\nCheck a feed is valid with gtfs_kit.\n\n\nprint_alerts\nPrint validity errors & warning messages in full.\n\n\nsave\nSave the cleaned gtfs feed.\n\n\nsummarise_routes\nProduce a summarised table of route statistics by day of week.\n\n\nsummarise_trips\nProduce a summarised table of trip statistics by day of week.\n\n\nviz_stops\nVisualise the stops on a map as points or convex hull. Writes file.\n\n\n\n\n\nvalidation.GtfsInstance.clean_feed(validate=False, fast_travel=False)\nAttempt to clean feed using gtfs_kit.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalidate\nbool\nWhether or not to validate the dataframe before cleaning, by default False.\nFalse\n\n\nfast_travel\nbool\nWhether or not to clean warnings related to fast travel, by default False.\nFalse\n\n\n\n\n\n\n\nvalidation.GtfsInstance.ensure_populated_calendar()\nIf calendar is absent, creates one from calendar_dates.\nSaves calendar table to feed.calendar. Shallow wrapper around gtfs.calendar.create_calendar_from_dates.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nFileNotFoundError\nCalendar and calendar_dates are missing, GTFS is invalid.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.filter_to_bbox(bbox, crs='epsg:4326')\nVery shallow wrapper around filter_gfts().\nFilters GTFS to a bbox.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbbox\nUnion[list, GeoDataFrame]\nThe bbox to filter the GTFS to. Leave as none if the GTFS does not need to be cropped. Format - [xmin, ymin, xmax, ymax]\nrequired\n\n\ncrs\nUnion[str, int]\nThe CRS of the given bbox, by default “epsg:4326”\n'epsg:4326'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nvalidation.GtfsInstance.filter_to_date(dates)\nVery shallow wrapper around filter_gtfs().\nFilters GTFS to date(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndates\nUnion[str, list]\nThe date(s) to filter the GTFS to\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nvalidation.GtfsInstance.get_gtfs_files()\nReturn a list of files present in the GTFS feed.\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nA list of files that present within the GTFS file\n\n\n\n\n\n\n\nvalidation.GtfsInstance.get_route_modes()\nSummarise the available routes by their associated route_type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.core.frame.DataFrame\nSummary table of route counts by transport mode.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.html_report(report_dir='outputs', overwrite=False, summary_type='mean', extended_validation=False, clean_feed=True)\nGenerate a HTML report describing the GTFS data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nreport_dir\nUnion[str, pathlib.Path]\nThe directory to save the report to, by default “outputs”\n'outputs'\n\n\noverwrite\nbool\nWhether or not to overwrite the existing report if it already exists in the report_dir, by default False\nFalse\n\n\nsummary_type\nstr\nThe type of summary to show on the summaries on the gtfs report, by default “mean”\n'mean'\n\n\nextended_validation\nbool\nWhether or not to create extended reports for gtfs validation errors/warnings, by default False\nFalse\n\n\nclean_feed\nbool\nWhether or not to clean the feed before validating, by default True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nAn error raised if the type of summary passed is invalid\n\n\n\n\n\n\n\nvalidation.GtfsInstance.is_valid(far_stops=False)\nCheck a feed is valid with gtfs_kit.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfar_stops\nbool\nWhether or not to perform validation for far stops (both between consecutive stops and over multiple stops), by default False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.core.frame.DataFrame\nTable of errors, warnings & their descriptions.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.print_alerts(alert_type='error')\nPrint validity errors & warning messages in full.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nalert_type\nstr\nThe alert type to print. Also accepts “warning”. Defaults to “error”.\n'error'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAttributeError\nNo validity_df() attrubute was found.\n\n\nUserWarning\nNo alerts of the specified alert_type were found.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.save(path, overwrite=False)\nSave the cleaned gtfs feed.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, pathlib.Path]\nThe path to save the GTFS file to. E.g., outputs/cleaned_gtfs.zip\nrequired\n\n\noverwrite\nbool\nWhether or not to overwrite any pre-existing files at the given path\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nvalidation.GtfsInstance.summarise_routes(summ_ops=[np.min, np.max, np.mean, np.median], return_summary=True)\nProduce a summarised table of route statistics by day of week.\nFor route count summaries, function counts route_id only, irrespective of which service_id the routes map to. If the services run on different calendar days, they will be counted separately. In cases where more than one service runs the same route on the same day, these will not be counted as distinct routes.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsumm_ops\nlist\nA list of operators used to get a summary of a given day, by default [np.min, np.max, np.mean, np.median].\n[np.min, np.max, np.mean, np.median]\n\n\nreturn_summary\nbool\nWhen True, a summary is returned. When False, route data for each date is returned, by default True.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA dataframe containing either summarised results or dated route data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n1. return_summary is not of type pd.df. 2. summ_ops must be a numpy function or a list. 3. Each item in a summ_ops list must be a function. 4. Each item in a summ_ops list must be a numpy namespace export.\n\n\nNotImplementedError\nsumm_ops is a function not exported from numpy.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.summarise_trips(summ_ops=[np.min, np.max, np.mean, np.median], return_summary=True)\nProduce a summarised table of trip statistics by day of week.\nFor trip count summaries, function counts distinct trip_id only. These are then summarised into average/median/min/max (default) number of trips per day. Raw data for each date can also be obtained by setting the ‘return_summary’ parameter to False (bool).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsumm_ops\nlist\nA list of operators used to get a summary of a given day, by default [np.min, np.max, np.mean, np.median].\n[np.min, np.max, np.mean, np.median]\n\n\nreturn_summary\nbool\nWhen True, a summary is returned. When False, trip data for each date is returned, by default True.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA dataframe containing either summarised results or dated trip data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n1. return_summary is not of type pd.df. 2. summ_ops must be a numpy function or a list. 3. Each item in a summ_ops list must be a function. 4. Each item in a summ_ops list must be a numpy namespace export.\n\n\nNotImplementedError\nsumm_ops is a function not exported from numpy.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.viz_stops(out_pth, geoms='point', geom_crs=27700, create_out_parent=False, filtered_only=True)\nVisualise the stops on a map as points or convex hull. Writes file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nout_pth\nUnion[str, pathlib.Path]\nPath to write the map file html document to, including the file name. Must end with ‘.html’ file extension.\nrequired\n\n\ngeoms\nstr\nType of map to plot. If geoms=point (the default) uses gtfs_kit to map point locations of available stops. If geoms=hull, calculates the convex hull & its area, defaults to “point”.\n'point'\n\n\ngeom_crs\nUnion[str, int]\nGeometric CRS to use for the calculation of the convex hull area only, defaults to “27700” (OSGB36, British National Grid).\n27700\n\n\ncreate_out_parent\nbool\nShould the parent directory of out_pth be created if not found, defaults to False.\nFalse\n\n\nfiltered_only\nbool\nWhen True, only stops referenced within stop_times.txt will be plotted. When False, stops referenced in stops.txt will be plotted. Note that gtfs_kit filtering behaviour removes stops from stop_times.txt but not stops.txt, defaults to True.\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n1. out_pth is not either of string or pathlib.PosixPath. 2. geoms is not of type str 3. geom_crs is not of type str or int 4. create_out_parent or filtered_only are not of type bool\n\n\nFileNotFoundError\nRaised if the parent directory of out_pth could not be found on disk and create_out_parent is False.\n\n\nKeyError\nThe stops table has no ‘stops_code’ column.\n\n\nUserWarning\nIf the file extension of out_pth is not .html, the extension will be changed to .html.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "validation"
    ]
  },
  {
    "objectID": "docs/reference/validation.html#classes",
    "href": "docs/reference/validation.html#classes",
    "title": "validation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nGtfsInstance\nCreate a feed instance for validation, cleaning & visualisation.\n\n\n\n\n\nvalidation.GtfsInstance(self, gtfs_pth, units='km', route_lookup_pth=None)\nCreate a feed instance for validation, cleaning & visualisation.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs_pth\nUnion[str, bytes, os.PathLike]\nFile path to GTFS archive.\nrequired\n\n\nunits\n(str, optionl)\nSpatial units of the GTFS file, defaults to “km”.\n'km'\n\n\nroute_lookup_pth\nUnion[str, pathlib.Path]\nThe path to the route type lookup. If left empty, the default path will be used. When None, route lookup table is read from file saved within this package, defaults to None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nfeed\ngtfs_kit.Feed\nA gtfs_kit feed produced using the files at gtfs_pth on init.\n\n\ngtfs_path\nUnion[str, pathlib.Path]\nThe path to the GTFS archive.\n\n\nfile_list\nlist\nFiles in the GTFS archive.\n\n\nvalidity_df\npd.DataFrame\nTable of GTFS errors, warnings & their descriptions.\n\n\ndated_trip_counts\npd.DataFrame\nDated trip counts by modality.\n\n\ndaily_trip_summary\npd.DataFrame\nSummarised trip results by day of the week and modality.\n\n\ndaily_route_summary\npd.DataFrame\nDated route counts by modality.\n\n\nroute_mode_summary_df\npd.DataFrame\nSummarised route counts by day of the week and modality.\n\n\npre_processed_trips\npd.DataFrame\nA table of pre-processed trip data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n1. pth is not either of string or pathlib.Path. 2. units is not of type str.\n\n\nFileExistsError\npth does not exist on disk.\n\n\nValueError\n1. pth does not have the expected file extension(s). 2. units are not one of: “m”, “km”, “metres”, “meters”, “kilometres”, “kilometers”.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nclean_feed\nAttempt to clean feed using gtfs_kit.\n\n\nensure_populated_calendar\nIf calendar is absent, creates one from calendar_dates.\n\n\nfilter_to_bbox\nVery shallow wrapper around filter_gfts().\n\n\nfilter_to_date\nVery shallow wrapper around filter_gtfs().\n\n\nget_gtfs_files\nReturn a list of files present in the GTFS feed.\n\n\nget_route_modes\nSummarise the available routes by their associated route_type.\n\n\nhtml_report\nGenerate a HTML report describing the GTFS data.\n\n\nis_valid\nCheck a feed is valid with gtfs_kit.\n\n\nprint_alerts\nPrint validity errors & warning messages in full.\n\n\nsave\nSave the cleaned gtfs feed.\n\n\nsummarise_routes\nProduce a summarised table of route statistics by day of week.\n\n\nsummarise_trips\nProduce a summarised table of trip statistics by day of week.\n\n\nviz_stops\nVisualise the stops on a map as points or convex hull. Writes file.\n\n\n\n\n\nvalidation.GtfsInstance.clean_feed(validate=False, fast_travel=False)\nAttempt to clean feed using gtfs_kit.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalidate\nbool\nWhether or not to validate the dataframe before cleaning, by default False.\nFalse\n\n\nfast_travel\nbool\nWhether or not to clean warnings related to fast travel, by default False.\nFalse\n\n\n\n\n\n\n\nvalidation.GtfsInstance.ensure_populated_calendar()\nIf calendar is absent, creates one from calendar_dates.\nSaves calendar table to feed.calendar. Shallow wrapper around gtfs.calendar.create_calendar_from_dates.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nFileNotFoundError\nCalendar and calendar_dates are missing, GTFS is invalid.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.filter_to_bbox(bbox, crs='epsg:4326')\nVery shallow wrapper around filter_gfts().\nFilters GTFS to a bbox.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbbox\nUnion[list, GeoDataFrame]\nThe bbox to filter the GTFS to. Leave as none if the GTFS does not need to be cropped. Format - [xmin, ymin, xmax, ymax]\nrequired\n\n\ncrs\nUnion[str, int]\nThe CRS of the given bbox, by default “epsg:4326”\n'epsg:4326'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nvalidation.GtfsInstance.filter_to_date(dates)\nVery shallow wrapper around filter_gtfs().\nFilters GTFS to date(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndates\nUnion[str, list]\nThe date(s) to filter the GTFS to\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nvalidation.GtfsInstance.get_gtfs_files()\nReturn a list of files present in the GTFS feed.\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist\nA list of files that present within the GTFS file\n\n\n\n\n\n\n\nvalidation.GtfsInstance.get_route_modes()\nSummarise the available routes by their associated route_type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.core.frame.DataFrame\nSummary table of route counts by transport mode.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.html_report(report_dir='outputs', overwrite=False, summary_type='mean', extended_validation=False, clean_feed=True)\nGenerate a HTML report describing the GTFS data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nreport_dir\nUnion[str, pathlib.Path]\nThe directory to save the report to, by default “outputs”\n'outputs'\n\n\noverwrite\nbool\nWhether or not to overwrite the existing report if it already exists in the report_dir, by default False\nFalse\n\n\nsummary_type\nstr\nThe type of summary to show on the summaries on the gtfs report, by default “mean”\n'mean'\n\n\nextended_validation\nbool\nWhether or not to create extended reports for gtfs validation errors/warnings, by default False\nFalse\n\n\nclean_feed\nbool\nWhether or not to clean the feed before validating, by default True\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nAn error raised if the type of summary passed is invalid\n\n\n\n\n\n\n\nvalidation.GtfsInstance.is_valid(far_stops=False)\nCheck a feed is valid with gtfs_kit.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfar_stops\nbool\nWhether or not to perform validation for far stops (both between consecutive stops and over multiple stops), by default False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.core.frame.DataFrame\nTable of errors, warnings & their descriptions.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.print_alerts(alert_type='error')\nPrint validity errors & warning messages in full.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nalert_type\nstr\nThe alert type to print. Also accepts “warning”. Defaults to “error”.\n'error'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAttributeError\nNo validity_df() attrubute was found.\n\n\nUserWarning\nNo alerts of the specified alert_type were found.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.save(path, overwrite=False)\nSave the cleaned gtfs feed.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, pathlib.Path]\nThe path to save the GTFS file to. E.g., outputs/cleaned_gtfs.zip\nrequired\n\n\noverwrite\nbool\nWhether or not to overwrite any pre-existing files at the given path\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nvalidation.GtfsInstance.summarise_routes(summ_ops=[np.min, np.max, np.mean, np.median], return_summary=True)\nProduce a summarised table of route statistics by day of week.\nFor route count summaries, function counts route_id only, irrespective of which service_id the routes map to. If the services run on different calendar days, they will be counted separately. In cases where more than one service runs the same route on the same day, these will not be counted as distinct routes.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsumm_ops\nlist\nA list of operators used to get a summary of a given day, by default [np.min, np.max, np.mean, np.median].\n[np.min, np.max, np.mean, np.median]\n\n\nreturn_summary\nbool\nWhen True, a summary is returned. When False, route data for each date is returned, by default True.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA dataframe containing either summarised results or dated route data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n1. return_summary is not of type pd.df. 2. summ_ops must be a numpy function or a list. 3. Each item in a summ_ops list must be a function. 4. Each item in a summ_ops list must be a numpy namespace export.\n\n\nNotImplementedError\nsumm_ops is a function not exported from numpy.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.summarise_trips(summ_ops=[np.min, np.max, np.mean, np.median], return_summary=True)\nProduce a summarised table of trip statistics by day of week.\nFor trip count summaries, function counts distinct trip_id only. These are then summarised into average/median/min/max (default) number of trips per day. Raw data for each date can also be obtained by setting the ‘return_summary’ parameter to False (bool).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsumm_ops\nlist\nA list of operators used to get a summary of a given day, by default [np.min, np.max, np.mean, np.median].\n[np.min, np.max, np.mean, np.median]\n\n\nreturn_summary\nbool\nWhen True, a summary is returned. When False, trip data for each date is returned, by default True.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nA dataframe containing either summarised results or dated trip data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n1. return_summary is not of type pd.df. 2. summ_ops must be a numpy function or a list. 3. Each item in a summ_ops list must be a function. 4. Each item in a summ_ops list must be a numpy namespace export.\n\n\nNotImplementedError\nsumm_ops is a function not exported from numpy.\n\n\n\n\n\n\n\nvalidation.GtfsInstance.viz_stops(out_pth, geoms='point', geom_crs=27700, create_out_parent=False, filtered_only=True)\nVisualise the stops on a map as points or convex hull. Writes file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nout_pth\nUnion[str, pathlib.Path]\nPath to write the map file html document to, including the file name. Must end with ‘.html’ file extension.\nrequired\n\n\ngeoms\nstr\nType of map to plot. If geoms=point (the default) uses gtfs_kit to map point locations of available stops. If geoms=hull, calculates the convex hull & its area, defaults to “point”.\n'point'\n\n\ngeom_crs\nUnion[str, int]\nGeometric CRS to use for the calculation of the convex hull area only, defaults to “27700” (OSGB36, British National Grid).\n27700\n\n\ncreate_out_parent\nbool\nShould the parent directory of out_pth be created if not found, defaults to False.\nFalse\n\n\nfiltered_only\nbool\nWhen True, only stops referenced within stop_times.txt will be plotted. When False, stops referenced in stops.txt will be plotted. Note that gtfs_kit filtering behaviour removes stops from stop_times.txt but not stops.txt, defaults to True.\nTrue\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\n1. out_pth is not either of string or pathlib.PosixPath. 2. geoms is not of type str 3. geom_crs is not of type str or int 4. create_out_parent or filtered_only are not of type bool\n\n\nFileNotFoundError\nRaised if the parent directory of out_pth could not be found on disk and create_out_parent is False.\n\n\nKeyError\nThe stops table has no ‘stops_code’ column.\n\n\nUserWarning\nIf the file extension of out_pth is not .html, the extension will be changed to .html.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "validation"
    ]
  },
  {
    "objectID": "docs/reference/routes.html",
    "href": "docs/reference/routes.html",
    "title": "routes",
    "section": "",
    "text": "routes\nHelpers for working with routes.txt.\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_saved_route_type_lookup\nGet the locally saved route type lookup as a dataframe.\n\n\nscrape_route_type_lookup\nScrape a lookup of GTFS route_type codes to descriptions.\n\n\n\n\n\nroutes.get_saved_route_type_lookup(path=pathlib.Path(os.path.join(PKG_PATH, 'data', 'route_lookup.pkl')))\nGet the locally saved route type lookup as a dataframe.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, pathlib.Path]\nThe path to the route type lookup, defaults to os.path.join(PKG_PATH, “data”, “route_lookup.pkl”)\npathlib.Path(os.path.join(PKG_PATH, 'data', 'route_lookup.pkl'))\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nThe route type lookup\n\n\n\n\n\n\n\nroutes.scrape_route_type_lookup(gtfs_url='https://gtfs.org/schedule/reference/', ext_spec_url='https://developers.google.com/transit/gtfs/reference/extended-route-types', extended_schema=True)\nScrape a lookup of GTFS route_type codes to descriptions.\nScrapes HTML tables from gtfs_url to provide a lookup of route_type codes to human readable descriptions. Useful for confirming available modes of transport within a GTFS. If extended_schema is True, then also include the proposed extension of route_type to the GTFS.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs_url\nstr\nThe url containing the GTFS accepted route_type codes. Defaults to “https://gtfs.org/schedule/reference/”.\n'https://gtfs.org/schedule/reference/'\n\n\next_spec_url\nstr\nThe url containing the table of the proposed extension to the GTFS schema for route_type codes. Defaults to ( “https://developers.google.com/transit/gtfs/reference/” “extended-route-types” ).\n'https://developers.google.com/transit/gtfs/reference/extended-route-types'\n\n\nextended_schema\nbool\nShould the extended schema table be scraped and included in the output? Defaults to True.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.core.frame.DataFrame\nA lookup of route_type codes to descriptions.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\ngtfs_url or ext_spec_url are not “http” or “https” protocol.\n\n\nTypeError\nextended_schema is not of type bool.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "routes"
    ]
  },
  {
    "objectID": "docs/reference/routes.html#functions",
    "href": "docs/reference/routes.html#functions",
    "title": "routes",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_saved_route_type_lookup\nGet the locally saved route type lookup as a dataframe.\n\n\nscrape_route_type_lookup\nScrape a lookup of GTFS route_type codes to descriptions.\n\n\n\n\n\nroutes.get_saved_route_type_lookup(path=pathlib.Path(os.path.join(PKG_PATH, 'data', 'route_lookup.pkl')))\nGet the locally saved route type lookup as a dataframe.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nUnion[str, pathlib.Path]\nThe path to the route type lookup, defaults to os.path.join(PKG_PATH, “data”, “route_lookup.pkl”)\npathlib.Path(os.path.join(PKG_PATH, 'data', 'route_lookup.pkl'))\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.DataFrame\nThe route type lookup\n\n\n\n\n\n\n\nroutes.scrape_route_type_lookup(gtfs_url='https://gtfs.org/schedule/reference/', ext_spec_url='https://developers.google.com/transit/gtfs/reference/extended-route-types', extended_schema=True)\nScrape a lookup of GTFS route_type codes to descriptions.\nScrapes HTML tables from gtfs_url to provide a lookup of route_type codes to human readable descriptions. Useful for confirming available modes of transport within a GTFS. If extended_schema is True, then also include the proposed extension of route_type to the GTFS.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs_url\nstr\nThe url containing the GTFS accepted route_type codes. Defaults to “https://gtfs.org/schedule/reference/”.\n'https://gtfs.org/schedule/reference/'\n\n\next_spec_url\nstr\nThe url containing the table of the proposed extension to the GTFS schema for route_type codes. Defaults to ( “https://developers.google.com/transit/gtfs/reference/” “extended-route-types” ).\n'https://developers.google.com/transit/gtfs/reference/extended-route-types'\n\n\nextended_schema\nbool\nShould the extended schema table be scraped and included in the output? Defaults to True.\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npd.core.frame.DataFrame\nA lookup of route_type codes to descriptions.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\ngtfs_url or ext_spec_url are not “http” or “https” protocol.\n\n\nTypeError\nextended_schema is not of type bool.",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "routes"
    ]
  },
  {
    "objectID": "docs/reference/gtfs_utils.html",
    "href": "docs/reference/gtfs_utils.html",
    "title": "gtfs_utils",
    "section": "",
    "text": "gtfs_utils\nUtility functions for GTFS archives.\n\n\n\n\n\nName\nDescription\n\n\n\n\nbbox_filter_gtfs\nFilter a GTFS feed to any routes intersecting with a bounding box.\n\n\nconvert_pandas_to_plotly\nConvert a pandas dataframe to a visual plotly figure.\n\n\nfilter_gtfs\nFilter the GTFS to either a bbox or a date.\n\n\nfilter_gtfs_around_trip\nFilter a GTFS file to an area around a given trip in the GTFS.\n\n\n\n\n\ngtfs_utils.bbox_filter_gtfs(in_pth=(os.path.join(PKG_PATH, 'data', 'newport-20230613_gtfs.zip')), out_pth=pathlib.Path(here('data/external/filtered_gtfs.zip')), bbox=[-3.077081, 51.52222, -2.925075, 51.593596], units='km', crs='epsg:4326', filter_dates=[])\nFilter a GTFS feed to any routes intersecting with a bounding box.\nOptionally filter to a list of given dates.\nWARNING: THIS FUNCTION IS DEPRECATED AND WILL BE REMOVED IN A FUTURE VERSION. USE filter_gtfs() INSTEAD.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nin_pth\nUnion[pathlib.Path, str]\nPath to the unfiltered GTFS feed. Defaults to os.path.join(PKG_PATH, “data”, “newport-20230613_gtfs.zip”).\n(os.path.join(PKG_PATH, 'data', 'newport-20230613_gtfs.zip'))\n\n\nout_pth\nUnion[pathlib.Path, str]\nPath to write the filtered feed to. Defaults to here(“data/external/filtered_gtfs.zip”).\npathlib.Path(here('data/external/filtered_gtfs.zip'))\n\n\nbbox\nUnion[gpd.GeoDataFrame, list(float)]\nA list of x and y values in the order of minx, miny, maxx, maxy. Defaults to [-3.077081, 51.52222, -2.925075, 51.593596].\n[-3.077081, 51.52222, -2.925075, 51.593596]\n\n\nunits\nstr\nDistance units of the original GTFS. Defaults to “km”.\n'km'\n\n\ncrs\nstr\nWhat projection should the bbox_list be interpreted as. Defaults to “epsg:4326” for lat long.\n'epsg:4326'\n\n\nfilter_dates\nlist\nA list of dates to restrict the feed to. Not providing filter_dates means that date filtering will not be applied. Defaults to [].\n[]\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\nbbox is not of type list or gpd.GeoDataFrame. units or crs are not of type str. out_pth or in_pth are not of types str or pathlib.Path. Elements of a bbox list are not of type float.\n\n\nFileExistsError\nin_pth does not exist on disk.\n\n\nValueError\nin_pth or out_pth does not have the expected .zip extension.\n\n\n\n\n\n\n\ngtfs_utils.convert_pandas_to_plotly(df, return_html=False)\nConvert a pandas dataframe to a visual plotly figure.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npd.DataFrame\nA pandas dataframe to convert to plotly (single index only)\nrequired\n\n\nreturn_html\nbool\nWhether or not to return the html element, by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ngo.Figure\nA plotly figure containing the drawn dataframe\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nLookupError\nAn error raised if an invalid colour scheme is passed\n\n\nTypeError\nAn error raised if the given pandas dataframe is MultiIndex\n\n\n\n\n\n\n\ngtfs_utils.filter_gtfs(gtfs, bbox=None, crs='epsg:4326', filter_dates=[])\nFilter the GTFS to either a bbox or a date.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GTFS to filter\nrequired\n\n\nbbox\nUnion[GeoDataFrame, list, None]\nThe bbox to filter the GTFS to. Leave as none if the GTFS does not need to be cropped. Format - [xmin, ymin, xmax, ymax], by default None\nNone\n\n\ncrs\nUnion[str, int]\nThe CRS of the given bbox, by default “epsg:4326”\n'epsg:4326'\n\n\nfilter_dates\nlist\nThe dates to filter the GTFS to. Leave as an empty list if you do not require the GTFS to be filtered to a date, by default []\n[]\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nRaised if any of the dates passed to ‘filter_dates’ isn’t present in the gtfs\n\n\n\n\n\n\n\ngtfs_utils.filter_gtfs_around_trip(gtfs, trip_id, buffer_dist=10000, units='m', crs='27700', out_pth=os.path.join('data', 'external', 'trip_gtfs.zip'))\nFilter a GTFS file to an area around a given trip in the GTFS.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GtfsInstance object to crop\nrequired\n\n\ntrip_id\nstr\nThe trip ID\nrequired\n\n\nbuffer_dist\nint\nThe distance to create a buffer around the trip, by default 10000\n10000\n\n\nunits\nstr\nDistance units of the original GTFS, by default “m”\n'm'\n\n\ncrs\nstr\nThe CRS to use for adding a buffer, by default “27700”\n'27700'\n\n\nout_pth\ntype\nWhere to save the new GTFS file, by default os.path.join(“data”, “external”, “trip_gtfs.zip”)\nos.path.join('data', 'external', 'trip_gtfs.zip')\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nAn error is raised if a shapeID is not available",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "gtfs_utils"
    ]
  },
  {
    "objectID": "docs/reference/gtfs_utils.html#functions",
    "href": "docs/reference/gtfs_utils.html#functions",
    "title": "gtfs_utils",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbbox_filter_gtfs\nFilter a GTFS feed to any routes intersecting with a bounding box.\n\n\nconvert_pandas_to_plotly\nConvert a pandas dataframe to a visual plotly figure.\n\n\nfilter_gtfs\nFilter the GTFS to either a bbox or a date.\n\n\nfilter_gtfs_around_trip\nFilter a GTFS file to an area around a given trip in the GTFS.\n\n\n\n\n\ngtfs_utils.bbox_filter_gtfs(in_pth=(os.path.join(PKG_PATH, 'data', 'newport-20230613_gtfs.zip')), out_pth=pathlib.Path(here('data/external/filtered_gtfs.zip')), bbox=[-3.077081, 51.52222, -2.925075, 51.593596], units='km', crs='epsg:4326', filter_dates=[])\nFilter a GTFS feed to any routes intersecting with a bounding box.\nOptionally filter to a list of given dates.\nWARNING: THIS FUNCTION IS DEPRECATED AND WILL BE REMOVED IN A FUTURE VERSION. USE filter_gtfs() INSTEAD.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nin_pth\nUnion[pathlib.Path, str]\nPath to the unfiltered GTFS feed. Defaults to os.path.join(PKG_PATH, “data”, “newport-20230613_gtfs.zip”).\n(os.path.join(PKG_PATH, 'data', 'newport-20230613_gtfs.zip'))\n\n\nout_pth\nUnion[pathlib.Path, str]\nPath to write the filtered feed to. Defaults to here(“data/external/filtered_gtfs.zip”).\npathlib.Path(here('data/external/filtered_gtfs.zip'))\n\n\nbbox\nUnion[gpd.GeoDataFrame, list(float)]\nA list of x and y values in the order of minx, miny, maxx, maxy. Defaults to [-3.077081, 51.52222, -2.925075, 51.593596].\n[-3.077081, 51.52222, -2.925075, 51.593596]\n\n\nunits\nstr\nDistance units of the original GTFS. Defaults to “km”.\n'km'\n\n\ncrs\nstr\nWhat projection should the bbox_list be interpreted as. Defaults to “epsg:4326” for lat long.\n'epsg:4326'\n\n\nfilter_dates\nlist\nA list of dates to restrict the feed to. Not providing filter_dates means that date filtering will not be applied. Defaults to [].\n[]\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\nbbox is not of type list or gpd.GeoDataFrame. units or crs are not of type str. out_pth or in_pth are not of types str or pathlib.Path. Elements of a bbox list are not of type float.\n\n\nFileExistsError\nin_pth does not exist on disk.\n\n\nValueError\nin_pth or out_pth does not have the expected .zip extension.\n\n\n\n\n\n\n\ngtfs_utils.convert_pandas_to_plotly(df, return_html=False)\nConvert a pandas dataframe to a visual plotly figure.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npd.DataFrame\nA pandas dataframe to convert to plotly (single index only)\nrequired\n\n\nreturn_html\nbool\nWhether or not to return the html element, by default False\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ngo.Figure\nA plotly figure containing the drawn dataframe\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nLookupError\nAn error raised if an invalid colour scheme is passed\n\n\nTypeError\nAn error raised if the given pandas dataframe is MultiIndex\n\n\n\n\n\n\n\ngtfs_utils.filter_gtfs(gtfs, bbox=None, crs='epsg:4326', filter_dates=[])\nFilter the GTFS to either a bbox or a date.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GTFS to filter\nrequired\n\n\nbbox\nUnion[GeoDataFrame, list, None]\nThe bbox to filter the GTFS to. Leave as none if the GTFS does not need to be cropped. Format - [xmin, ymin, xmax, ymax], by default None\nNone\n\n\ncrs\nUnion[str, int]\nThe CRS of the given bbox, by default “epsg:4326”\n'epsg:4326'\n\n\nfilter_dates\nlist\nThe dates to filter the GTFS to. Leave as an empty list if you do not require the GTFS to be filtered to a date, by default []\n[]\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nRaised if any of the dates passed to ‘filter_dates’ isn’t present in the gtfs\n\n\n\n\n\n\n\ngtfs_utils.filter_gtfs_around_trip(gtfs, trip_id, buffer_dist=10000, units='m', crs='27700', out_pth=os.path.join('data', 'external', 'trip_gtfs.zip'))\nFilter a GTFS file to an area around a given trip in the GTFS.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ngtfs\nGtfsInstance\nThe GtfsInstance object to crop\nrequired\n\n\ntrip_id\nstr\nThe trip ID\nrequired\n\n\nbuffer_dist\nint\nThe distance to create a buffer around the trip, by default 10000\n10000\n\n\nunits\nstr\nDistance units of the original GTFS, by default “m”\n'm'\n\n\ncrs\nstr\nThe CRS to use for adding a buffer, by default “27700”\n'27700'\n\n\nout_pth\ntype\nWhere to save the new GTFS file, by default os.path.join(“data”, “external”, “trip_gtfs.zip”)\nos.path.join('data', 'external', 'trip_gtfs.zip')\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nValueError\nAn error is raised if a shapeID is not available",
    "crumbs": [
      "API Reference",
      "`gtfs`",
      "gtfs_utils"
    ]
  },
  {
    "objectID": "docs/tutorials/index.html",
    "href": "docs/tutorials/index.html",
    "title": "GTFS",
    "section": "",
    "text": "In this tutorial we will learn how to validate and clean General Transit Feed Specification (GTFS) feeds. This is an important step to ensure quality in the inputs and reduce the computational cost of routing operations.\nWhile working towards this outcome, we will:\n\nDownload open source GTFS data.\nCarry out some basic checks across the entire GTFS feed.\nVisualise the GTFS feed’s stop locations on an interactive map.\nFilter the GTFS feed to a specific bounding box.\nFilter the GTFS feed to a specific date range.\nCheck if our filter operations have resulted in an empty feed.\nReverse-engineer a calendar.txt if it is missing.\nCreate summary tables of routes and trips in the feed.\nAttempt to clean the feed.\nWrite the filtered feed out to file.\n\n\n\n\nTo complete this tutorial, you will need:\n\npython 3.9\nStable internet connection\nInstalled the assess-gtfs package (see the getting started explanation for help)"
  },
  {
    "objectID": "docs/tutorials/index.html#introduction",
    "href": "docs/tutorials/index.html#introduction",
    "title": "GTFS",
    "section": "",
    "text": "In this tutorial we will learn how to validate and clean General Transit Feed Specification (GTFS) feeds. This is an important step to ensure quality in the inputs and reduce the computational cost of routing operations.\nWhile working towards this outcome, we will:\n\nDownload open source GTFS data.\nCarry out some basic checks across the entire GTFS feed.\nVisualise the GTFS feed’s stop locations on an interactive map.\nFilter the GTFS feed to a specific bounding box.\nFilter the GTFS feed to a specific date range.\nCheck if our filter operations have resulted in an empty feed.\nReverse-engineer a calendar.txt if it is missing.\nCreate summary tables of routes and trips in the feed.\nAttempt to clean the feed.\nWrite the filtered feed out to file.\n\n\n\n\nTo complete this tutorial, you will need:\n\npython 3.9\nStable internet connection\nInstalled the assess-gtfs package (see the getting started explanation for help)"
  },
  {
    "objectID": "docs/tutorials/index.html#working-with-gtfs",
    "href": "docs/tutorials/index.html#working-with-gtfs",
    "title": "GTFS",
    "section": "Working With GTFS",
    "text": "Working With GTFS\nLet’s import the necessary dependencies:\n\nimport datetime\nimport os\nimport pathlib\nimport subprocess\nimport tempfile\n\nimport geopandas as gpd\nimport plotly.express as px\nfrom shapely.geometry import Polygon\n\nfrom assess_gtfs.multi_validation import MultiGtfsInstance\n\nWe require a source of public transit schedule data in GTFS format. The French government publish all of their data, along with may useful validation tools to the website transport.data.gouv.fr.\n\nTaskHintSolution\n\n\nSearching through this site for various regions and data types, you may be able to find an example of GTFS for an area of interest. Make a note of the transport modality of your GTFS, is it bus, rail or something else?\nYou may wish to manually download at least one GTFS feed and store somewhere in your file system. Alternatively you may programmatically download the data, as in the solution here.\n\n\n\nBUS_URL = \"&lt;INSERT_SOME_URL_TO_BUS_GTFS&gt;\"\nRAIL_URL = \"&lt;INSERT_SOME_URL_TO_RAIL_GTFS&gt;\"\n\nBUS_PTH = \"&lt;INSERT_SOME_PATH_FOR_BUS_GTFS&gt;\"\nRAIL_PTH = \"&lt;INSERT_SOME_PATH_FOR_RAIL_GTFS&gt;\"\n\nsubprocess.run([\"curl\", BUS_URL, \"-o\", BUS_PTH])\nsubprocess.run([\"curl\", RAIL_URL, \"-o\", RAIL_PTH])\n\n\n\n\nBUS_URL = \"https://tsvc.pilote4.cityway.fr/api/Export/v1/GetExportedDataFile?ExportFormat=Gtfs&OperatorCode=RTM\"\nRAIL_URL = \"https://eu.ftp.opendatasoft.com/sncf/gtfs/export-intercites-gtfs-last.zip\"\n# using tmp for tutorial but not necessary\ntmp_path = tempfile.TemporaryDirectory()\nbus_path = os.path.join(tmp_path.name, \"rtm_gtfs.zip\")\nrail_path = os.path.join(tmp_path.name, \"intercity_rail_gtfs.zip\")\nsubprocess.run([\"curl\", BUS_URL, \"-o\", bus_path])\nsubprocess.run([\"curl\", RAIL_URL, \"-o\", rail_path])\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  2 3931k    2 86559    0     0  72816      0  0:00:55  0:00:01  0:00:54 72799 23 3931k   23  929k    0     0   436k      0  0:00:09  0:00:02  0:00:07  436k 48 3931k   48 1903k    0     0   605k      0  0:00:06  0:00:03  0:00:03  605k 77 3931k   77 3037k    0     0   736k      0  0:00:05  0:00:04  0:00:01  735k100 3931k  100 3931k    0     0   784k      0  0:00:05  0:00:05 --:--:--  806k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100 91397  100 91397    0     0   178k      0 --:--:-- --:--:-- --:--:--  177k\n\n\nCompletedProcess(args=['curl', 'https://eu.ftp.opendatasoft.com/sncf/gtfs/export-intercites-gtfs-last.zip', '-o', '/tmp/tmpf86utho5/intercity_rail_gtfs.zip'], returncode=0)\n\n\n\n\n\nNow that we have ingested the GTFS feed(s), you may wish to open the files up on your file system and inspect the contents. GTFS feeds come in compressed formats and contain multiple text files. These files can be read together, a bit like a relational database, to produce a feed object that is useful when undertaking routing with public transport modalities.\nTo do this, we will need to use a class from the assess-gtfs package called MultiGtfsInstance. Take a look at the MultiGtfsInstance API documentation for full details on how this class works. You may wish to keep this page open for reference in later tasks.\nMultiGtfsInstance; as the name sounds; can cope with multiple GTFS feeds at a time. If you have chosen to download several feeds, then point the path parameter at a directory that contains all of the feeds. If you have chosen to download a single feed, then you may pass the full path to the feed.\n\nTaskHintSolution\n\n\nInstantiate a feed object by pointing the MultiGtfsInstance class at a path to the GTFS feed(s) that you have downloaded. Once you have successfully instantiated feed, inspect the correct attribute in order to confirm the number of separate feeds instances contained within it.\n\n\n\ngtfs_pth = \"&lt;INSERT_PATH_TO_GTFS&gt;\"\nfeed = MultiGtfsInstance(path=gtfs_pth)\nprint(len(feed.&lt;INSERT_CORRECT_ATTRIBUTE&gt;))\n\n\n\n\ngtfs_pth = pathlib.Path(tmp_path.name) # need to use pathlib for tmp_path\nfeed = MultiGtfsInstance(path=gtfs_pth)\nprint(f\"There are {len(feed.instances)} feed instances\")\n\nThere are 2 feed instances\n\n\n\n\n\nEach individual feed can be accessed separately. Their contents should confirm their file contents on disk. The GtfsInstance api documentation can be used to view the methods and attributes available for the following task.\n\nTaskHintSolution\n\n\nBy accessing the appropriate attribute, print out the first 5 stops of the first instance within the feed object.\n\n\n\nfeed.&lt;INSERT_CORRECT_ATTR&gt;[0].feed.stops.&lt;INSERT_CORRECT_METHOD&gt;(5)\n\nThese records will match the contents of the stops.txt file within the feed that you downloaded.\n\n\n\n\nfeed.instances[0].feed.stops.head(5)\n\n\n\n\n\n\n\n\nstop_id\nstop_name\nstop_desc\nstop_lat\nstop_lon\nzone_id\nstop_url\nlocation_type\nparent_station\n\n\n\n\n0\nStopArea:OCE87393009\nVersailles Chantiers\nNaN\n48.795826\n2.135883\nNaN\nNaN\n1\nNaN\n\n\n1\nStopPoint:OCEOUIGO-87393009\nVersailles Chantiers\nNaN\n48.795826\n2.135883\nNaN\nNaN\n0\nStopArea:OCE87393009\n\n\n2\nStopArea:OCE87393579\nMassy-Palaiseau\nNaN\n48.726421\n2.257528\nNaN\nNaN\n1\nNaN\n\n\n3\nStopPoint:OCEOUIGO-87393579\nMassy-Palaiseau\nNaN\n48.726421\n2.257528\nNaN\nNaN\n0\nStopArea:OCE87393579\n\n\n4\nStopArea:OCE87394007\nChartres\nNaN\n48.448202\n1.481313\nNaN\nNaN\n1\nNaN"
  },
  {
    "objectID": "docs/tutorials/index.html#checking-validity",
    "href": "docs/tutorials/index.html#checking-validity",
    "title": "GTFS",
    "section": "Checking Validity",
    "text": "Checking Validity\nTransport routing operations require services that run upon a specified date. It is a useful sanity check to confirm that the dates that you expect to perform routing on exist within the GTFS feed. To do this, we can use the get_dates() method to print out the first and last date in the available date range, as below.\n\ns0, e0 = feed.get_dates()\nprint(f\"Feed starts at: {s0}\\nFeed ends at: {e0}\")\n\nFeed starts at: 20240703\nFeed ends at: 20241002\n\n\n\nTaskHintSolution\n\n\nHow can we have this method print out the full list of dates available within the feed?\n\n\nExamine the MultiGtfsInstance api reference and find the name of the parameter that controls the behaviour of get_dates().\n\n\n\n\nfeed.get_dates(return_range=False)\n\n['20240703',\n '20240704',\n '20240705',\n '20240706',\n '20240707',\n '20240708',\n '20240709',\n '20240710',\n '20240711',\n '20240712',\n '20240713',\n '20240714',\n '20240715',\n '20240716',\n '20240717',\n '20240718',\n '20240719',\n '20240720',\n '20240721',\n '20240722',\n '20240723',\n '20240724',\n '20240725',\n '20240726',\n '20240727',\n '20240728',\n '20240729',\n '20240730',\n '20240731',\n '20240801',\n '20240802',\n '20240803',\n '20240804',\n '20240805',\n '20240806',\n '20240807',\n '20240808',\n '20240809',\n '20240810',\n '20240811',\n '20240812',\n '20240813',\n '20240814',\n '20240815',\n '20240816',\n '20240817',\n '20240818',\n '20240819',\n '20240820',\n '20240821',\n '20240822',\n '20240823',\n '20240824',\n '20240825',\n '20240826',\n '20240827',\n '20240828',\n '20240829',\n '20240830',\n '20240831',\n '20240901',\n '20240902',\n '20240903',\n '20240904',\n '20240905',\n '20240906',\n '20240907',\n '20240908',\n '20240909',\n '20240910',\n '20240911',\n '20240912',\n '20240913',\n '20240914',\n '20240915',\n '20240916',\n '20240917',\n '20240918',\n '20240919',\n '20240920',\n '20240921',\n '20240922',\n '20240923',\n '20240924',\n '20240925',\n '20240926',\n '20240927',\n '20240928',\n '20240929',\n '20240930',\n '20241001',\n '20241002']\n\n\n\n\n\n\nOpenly published GTFS feeds from a variety of different providers have varying degrees of quality and not all feeds strictly adhere to the defined specification for this type of data. When working with new sources of GTFS, it is advisable to investigate the types of errors or warnings associated with your particular feed(s).\n\nTaskHintSolution\n\n\nCheck if the feed you’ve instantiated contains valid GTFS.\n\n\nCheck the api reference for validation.GtfsInstance for an appropriate method.\n\n\n\n\nfeed.is_valid()\n\n  0%|          | 0/2 [00:00&lt;?, ?it/s]Validating GTFS from path /tmp/tmpf86utho5/intercity_rail_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]Validating GTFS from path /tmp/tmpf86utho5/intercity_rail_gtfs.zip:  50%|█████     | 1/2 [00:00&lt;00:00,  5.10it/s]Validating GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip:  50%|█████     | 1/2 [00:00&lt;00:00,  5.10it/s]           Validating GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:02&lt;00:00,  1.68s/it]Validating GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:02&lt;00:00,  1.46s/it]\n\n\n\n\n\n\n\n\n\ntype\nmessage\ntable\nrows\nGTFS\n\n\n\n\n0\nwarning\nUnrecognized column feed_id\nfeed_info\n[]\n/tmp/tmpf86utho5/intercity_rail_gtfs.zip\n\n\n1\nwarning\nUnrecognized column conv_rev\nfeed_info\n[]\n/tmp/tmpf86utho5/intercity_rail_gtfs.zip\n\n\n2\nwarning\nUnrecognized column plan_rev\nfeed_info\n[]\n/tmp/tmpf86utho5/intercity_rail_gtfs.zip\n\n\n3\nwarning\nRepeated pair (route_short_name, route_long_name)\nroutes\n[16, 17, 18, 19, 20]\n/tmp/tmpf86utho5/intercity_rail_gtfs.zip\n\n\n4\nwarning\nRepeated pair (trip_id, departure_time)\nstop_times\n[1352, 1361, 1363, 1367, 1372, 1375, 1377, 138...\n/tmp/tmpf86utho5/rtm_gtfs.zip\n\n\n5\nwarning\nStop has no stop times\nstops\n[146, 1498, 1499, 2130]\n/tmp/tmpf86utho5/rtm_gtfs.zip\n\n\n\n\n\n\n\n\n\n\n\nNote that it is common to come across multiple warnings when working with GTFS. Many providers include additional columns that are not part of the GTFS. This typically poses no problem when using the feed for routing operations.\nIn certain feeds, you may notice errors flagged due to unrecognised route types. This is because certain providers publish feeds that conform to Google’s proposed GTFS extension. Although flagged as an error, valid codes associated with the proposed extension typically do not cause problems with routing operations."
  },
  {
    "objectID": "docs/tutorials/index.html#viz-stops",
    "href": "docs/tutorials/index.html#viz-stops",
    "title": "GTFS",
    "section": "Viz Stops",
    "text": "Viz Stops\nA sensible check when working with GTFS for an area of interest, is to visualise the stop locations of your feed.\n\nTaskHintSolution\n\n\nBy accessing an appropriate method for your feed, plot the stop locations on an interactive folium map.\n\n\nInspect the MultiGtfsInstance api reference for the appropriate method.\n\nfeed.viz_...()\n\n\n\n\nfeed.viz_stops()\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\n\nBy inspecting the location of the stops, you can visually assess that they concur with the road network depicted on the folium basemap."
  },
  {
    "objectID": "docs/tutorials/index.html#filtering-gtfs",
    "href": "docs/tutorials/index.html#filtering-gtfs",
    "title": "GTFS",
    "section": "Filtering GTFS",
    "text": "Filtering GTFS\nCropping GTFS feeds can help optimise routing procedures. GTFS feeds can often be much larger than needed for smaller, more constrained routing operations. Holding an entire GTFS in memory may be unnecessary and burdensome. In this section, we will crop our feeds in two ways:\n\nSpatially by restricting the feed to a specified bounding box.\nTemporally by providing a date (or list of dates).\n\nBefore undertaking the filter operations, examine the size of our feed on disk:\n\nout = subprocess.run(\n    [\"du\", \"-sh\", tmp_path.name], capture_output=True, text=True)\nsize_out = out.stdout.strip().split(\"\\t\")[0]\nprint(f\"Unfiltered feed is: {size_out}\")\n\nUnfiltered feed is: 4.0M\n\n\n\nBy Bounding Box\nTo help understand the requirements for spatially cropping a feed, inspect the API documentation for the filter_to_bbox() method.\nTo perform this crop, we need to get a bounding box. This could be any boundary from an open service such as klokantech in csv format.\nThe bounding box should be in EPSG:4326 projection (longitude & latitude).\nBelow I define a bounding box and visualise for context. Feel free to update the code with your own bounding box values.\n\nBBOX = [4.932916,43.121441,5.644253,43.546931] # crop around Marseille\nxmin, ymin, xmax, ymax = BBOX\npoly = Polygon(((xmin,ymin), (xmin,ymax), (xmax,ymax), (xmax,ymin)))\npoly_gdf = gpd.GeoDataFrame({\"geometry\": poly}, crs=4326, index=[0])\npoly_gdf.explore()\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nTaskHintSolution\n\n\nCrop your feed to the extent of your bounding box.\n\n\nPass the BBOX list in [xmin, ymin, xmax, ymax] order to the filter_to_bbox() method.\n\n\n\nfeed.filter_to_bbox(BBOX)\n\n  0%|          | 0/2 [00:00&lt;?, ?it/s]Filtering GTFS from path /tmp/tmpf86utho5/intercity_rail_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]Filtering GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]           Filtering GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:00&lt;00:00,  6.62it/s]Filtering GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:00&lt;00:00,  6.60it/s]\n\n\n\n\n\nNotice that a progress bar confirms the number of successful filter operations performed depending on the number of separate GTFS zip files passed to MultiGtfsInstance.\nBelow I plot the filtered feed stop locations in relation to the bounding box used to restrict the feed’s extent.\n\nimap = feed.viz_stops()\npoly_gdf.explore(m=imap)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nAlthough there should be fewer stops observed, you will likely observe that stops outside of the bounding box you provided remain in the filtered feed. This is to be expected, particularly where GTFS feeds contain long-haul schedules that intersect with the bounding box that you provided.\n\n\nBy Date\nIf the routing analysis you wish to perform takes place over a specific time window, we can further reduce the GTFS data volume by restricting to dates. To do this, we need to specify either a single date string, or a list of date strings. The format of the date should be “YYYYMMDD”.\n\ntoday = datetime.datetime.today().strftime(format=\"%Y%m%d\")\nprint(f\"The date this document was updated at would be passed as: {today}\")\n\nThe date this document was updated at would be passed as: 20240704\n\n\n\nTaskHintSolution\n\n\nFilter your GTFS feed to a date or range of dates.\n\n\nPass either a single date string in “YYYYMMDD” format, or a list of date strings in this format, to the filter_to_date method. Print out the new start and end dates of your feed by calling the get_dates() method once more.\n\n\n\nfeed.filter_to_date(today)\nprint(f\"Filtered GTFS feed to {today}\")\n\n  0%|          | 0/2 [00:00&lt;?, ?it/s]Filtering GTFS from path /tmp/tmpf86utho5/intercity_rail_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]Filtering GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]           Filtering GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:00&lt;00:00,  3.30it/s]Filtering GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:00&lt;00:00,  3.30it/s]\n\n\nFiltered GTFS feed to 20240704\n\n\n\n\n\n\ns1, e1 = feed.get_dates()\nprint(f\"After filtering to {today}\\nstart date: {s1}\\nend date: {e1}\")\n\nAfter filtering to 20240704\nstart date: 20240703\nend date: 20240901\n\n\n\n\n\nNotice that even if we specify a single date to restrict the feed to, filter_to_date() may still return a range of dates. The filtering method restricts the GTFS to stops, trips or shapes active upon the specified date(s). If your GTFS contains trips/routes that are still active across a range of dates including the date you wish to restrict to, you will return the full range of that stop’s dates."
  },
  {
    "objectID": "docs/tutorials/index.html#check-empty-feeds",
    "href": "docs/tutorials/index.html#check-empty-feeds",
    "title": "GTFS",
    "section": "Check Empty Feeds",
    "text": "Check Empty Feeds\nAfter performing the filter operations on GTFS, it is advisable to check in case any of the filtered feeds are now empty. Empty feeds can cause errors when undertaking routing analysis. Empty feeds can easily arise when filtering GTFS to mismatched dates or bounding boxes.\nWe check for empty feeds in the following way:\n\nfeed.validate_empty_feeds()\n\n[]"
  },
  {
    "objectID": "docs/tutorials/index.html#create-calendar",
    "href": "docs/tutorials/index.html#create-calendar",
    "title": "GTFS",
    "section": "Create Calendar",
    "text": "Create Calendar\nOccasionally, providers will publish feeds that use a calendar-dates.txt file rather than a calendar.txt. This is permitted within GTFS and is an alternative approach to encoding the same sort of information about the feed timetable.\nHowever, missing calendar.txt files currently cause exceptions when attempting to route with these feeds with r5py. To avoid this issue, we can use a calendar-dates.txt to populate the required calendar.txt file.\nWe can check whether any of our feed instances have no calendar file:\n\nfor i, inst in enumerate(feed.instances):\n    if inst.feed.calendar is None:\n        problem_ind = i\nprint(f\"Feed instance {i} has no calendar.txt\")\n\nFeed instance 1 has no calendar.txt\n\n\n\nTaskHintSolution\n\n\nIf any of your feeds are missing calendars, ensure that these files are created from the calendar-dates files. Once complete, print out the head of the calendar table to ensure it is populated.\n\n\nExamine the MultiGtfsInstance api reference to find the appropriate method. Access the calendar DataFrame attribute from the same feed and print the first few rows.\n\nfeed.&lt;INSERT_CORRECT_METHOD&gt;()\nprint(feed.instances[&lt;INDEX_OF_MISSING_CALENDAR&gt;].feed.calendar.head())\n\n\n\n\nfeed.ensure_populated_calendars()\n\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/validation.py:294: UserWarning:\n\nNo calendar found for /tmp/tmpf86utho5/intercity_rail_gtfs.zip. Creating from calendar dates\n\n\n\n\nprint(\"Newly populated calendar table:\")\nprint(feed.instances[problem_ind].feed.calendar.head())\n\nNewly populated calendar table:\n  service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n0     000027       0        0          0         1       0         0       0   \n1     000243       0        0          0         1       0         0       0   \n2     000247       0        0          0         1       0         0       0   \n3     000267       0        0          0         1       0         0       0   \n4     000309       0        0          0         1       0         0       0   \n\n  start_date  end_date  \n0   20240704  20240704  \n1   20240704  20240704  \n2   20240704  20240704  \n3   20240704  20240704  \n4   20240704  20240704"
  },
  {
    "objectID": "docs/tutorials/index.html#trip-and-route-summaries",
    "href": "docs/tutorials/index.html#trip-and-route-summaries",
    "title": "GTFS",
    "section": "Trip and Route Summaries",
    "text": "Trip and Route Summaries\nNow that we have ensured all GTFS instances have a calendar table, we can calculate tables of counts and other summary statistics on the routes and trips within the feed.\n\nTaskHintSolution\n\n\nPrint 2 summary tables:\n\nCounts for routes on every date in the feed.\nStatistics for trips on every day in the feed.\n\n\n\nExamine the api reference help for MultiGtfsInstance. Use the appropriate methods to produce the summaries.\n\nUse the default behaviour to produce the first table.\nEnsure that the appropriate method allowing stats for days of the week is toggled to True for the trip summary.\n\n\n\n\nfeed.summarise_routes()\n\n\n\n\n\n\n\n\ndate\nroute_type\nroute_count\n\n\n\n\n0\n2024-07-03\n0\n3\n\n\n1\n2024-07-03\n1\n2\n\n\n2\n2024-07-03\n3\n104\n\n\n3\n2024-07-03\n4\n3\n\n\n4\n2024-07-04\n0\n3\n\n\n...\n...\n...\n...\n\n\n136\n2024-08-30\n3\n84\n\n\n137\n2024-08-30\n4\n4\n\n\n138\n2024-08-31\n3\n20\n\n\n139\n2024-08-31\n4\n4\n\n\n140\n2024-09-01\n4\n4\n\n\n\n\n141 rows × 3 columns\n\n\n\n\nfeed.summarise_trips(to_days=True)\n\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/multi_validation.py:456: FutureWarning:\n\nThe provided callable &lt;function min at 0x7f58741ba8e0&gt; is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/multi_validation.py:456: FutureWarning:\n\nThe provided callable &lt;function max at 0x7f58741ba7a0&gt; is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/multi_validation.py:456: FutureWarning:\n\nThe provided callable &lt;function mean at 0x7f58741bb1a0&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n\n/opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/assess_gtfs/multi_validation.py:456: FutureWarning:\n\nThe provided callable &lt;function median at 0x7f5874115800&gt; is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n\n\n\n\n\n\n\n\n\n\nday\nroute_type\ntrip_count_max\ntrip_count_mean\ntrip_count_median\ntrip_count_min\n\n\n\n\n0\nmonday\n4\n165\n165.0\n165.0\n165\n\n\n1\nmonday\n3\n8792\n7700.0\n7544.0\n7544\n\n\n2\nmonday\n1\n816\n816.0\n816.0\n816\n\n\n3\nmonday\n0\n986\n986.0\n986.0\n986\n\n\n4\ntuesday\n4\n165\n165.0\n165.0\n165\n\n\n5\ntuesday\n0\n986\n986.0\n986.0\n986\n\n\n6\ntuesday\n3\n8628\n7680.0\n7544.0\n7544\n\n\n7\ntuesday\n1\n816\n816.0\n816.0\n816\n\n\n8\nwednesday\n4\n165\n156.0\n165.0\n87\n\n\n9\nwednesday\n0\n986\n986.0\n986.0\n986\n\n\n10\nwednesday\n1\n816\n816.0\n816.0\n816\n\n\n11\nwednesday\n3\n9267\n7856.0\n7544.0\n7544\n\n\n12\nthursday\n3\n9557\n7888.0\n7544.0\n7544\n\n\n13\nthursday\n2\n12\n12.0\n12.0\n12\n\n\n14\nthursday\n1\n816\n816.0\n816.0\n816\n\n\n15\nthursday\n4\n165\n165.0\n165.0\n165\n\n\n16\nthursday\n0\n986\n986.0\n986.0\n986\n\n\n17\nfriday\n1\n816\n816.0\n816.0\n816\n\n\n18\nfriday\n3\n8826\n7792.0\n7544.0\n7408\n\n\n19\nfriday\n4\n165\n165.0\n165.0\n165\n\n\n20\nfriday\n0\n986\n986.0\n986.0\n986\n\n\n21\nsaturday\n3\n8792\n7023.0\n7544.0\n1606\n\n\n22\nsaturday\n1\n816\n816.0\n816.0\n816\n\n\n23\nsaturday\n0\n986\n986.0\n986.0\n986\n\n\n24\nsaturday\n4\n165\n165.0\n165.0\n165\n\n\n25\nsunday\n3\n8792\n7700.0\n7544.0\n7544\n\n\n26\nsunday\n1\n816\n816.0\n816.0\n816\n\n\n27\nsunday\n0\n986\n986.0\n986.0\n986\n\n\n28\nsunday\n4\n165\n165.0\n165.0\n165\n\n\n\n\n\n\n\n\n\n\nFrom these summaries we can also create visualisations, such as a timeseries plot of trip counts by route type and date:\n\n# sort by route_type and date to order plot correctly\ndf = feed.summarise_trips().sort_values([\"route_type\", \"date\"])\nfig = px.line(\n    df,\n    x=\"date\",\n    y=\"trip_count\",\n    color=\"route_type\",\n    title=\"Trip Counts by Route Type and Date Across All Input GTFS Feeds\",\n)\n\n# set y axis min to zero, improve y axis formatting, and overall font style\nfig.update_yaxes(rangemode=\"tozero\", tickformat=\",.0f\")\nfig.update_layout(\n    font_family=\"Arial\",\n    title_font_family=\"Arial\",\n)\nfig.show()\n\n                                                \n\n\nVisualisations like this can be very helpful when reviewing the quality of the input GTFS feeds and determining a suitable routing analysis date."
  },
  {
    "objectID": "docs/tutorials/index.html#clean-feed",
    "href": "docs/tutorials/index.html#clean-feed",
    "title": "GTFS",
    "section": "Clean Feed",
    "text": "Clean Feed\nWe can attempt to remove common issues with GTFS feeds by running the clean_feeds() method. This may remove problems associated with trips, routes or where the specification is violated.\n\n\nfeed.clean_feeds()\nfeed.is_valid()\n\n  0%|          | 0/2 [00:00&lt;?, ?it/s]Cleaning GTFS from path /tmp/tmpf86utho5/intercity_rail_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]/opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/gtfs_kit/cleaners.py:80: FutureWarning:\n\nDataFrame.applymap has been deprecated. Use DataFrame.map instead.\n\nCleaning GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]           /opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/gtfs_kit/cleaners.py:80: FutureWarning:\n\nDataFrame.applymap has been deprecated. Use DataFrame.map instead.\n\nCleaning GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:00&lt;00:00,  3.83it/s]Cleaning GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:00&lt;00:00,  3.83it/s]\n\n\nKeyError. Feed was not cleaned.\n\n\n  0%|          | 0/2 [00:00&lt;?, ?it/s]Validating GTFS from path /tmp/tmpf86utho5/intercity_rail_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]Validating GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]           Validating GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:01&lt;00:00,  1.88it/s]Validating GTFS from path /tmp/tmpf86utho5/rtm_gtfs.zip: 100%|██████████| 2/2 [00:01&lt;00:00,  1.88it/s]\n\n\n\n\n\n\n\n\n\ntype\nmessage\ntable\nrows\nGTFS\n\n\n\n\n0\nwarning\nUnrecognized column feed_id\nfeed_info\n[]\n/tmp/tmpf86utho5/intercity_rail_gtfs.zip\n\n\n1\nwarning\nUnrecognized column conv_rev\nfeed_info\n[]\n/tmp/tmpf86utho5/intercity_rail_gtfs.zip\n\n\n2\nwarning\nUnrecognized column plan_rev\nfeed_info\n[]\n/tmp/tmpf86utho5/intercity_rail_gtfs.zip\n\n\n3\nwarning\nRepeated pair (trip_id, departure_time)\nstop_times\n[1352, 1361, 1363, 1367, 1372, 1375, 1377, 138...\n/tmp/tmpf86utho5/rtm_gtfs.zip\n\n\n\n\n\n\n\n\nYou may note warnings printed to the console and a statement about whether a feed was successfully cleaned."
  },
  {
    "objectID": "docs/tutorials/index.html#write-filtered-feed",
    "href": "docs/tutorials/index.html#write-filtered-feed",
    "title": "GTFS",
    "section": "Write Filtered Feed",
    "text": "Write Filtered Feed\nOnce we have finished the filter and cleaning operations, we can now go ahead and write the feed out to disk, for use in future routing operations.\n\nTaskHintSolution\n\n\nWrite your filtered feed out to a new location on disk. Confirm that the size of the filtered feed on disk is smaller than that of the original feed.\n\n\n\nPass a string or a pathlike object to the save_feeds() method of MultiGtfsInstance.\nOnce the feed is written successfully, check the disk usage of the new filtered feed.\n\n\n\n\nfiltered_pth = os.path.join(tmp_path.name, \"filtered_feed\")\ntry:\n    os.mkdir(filtered_pth)\nexcept FileExistsError:\n    pass\nfeed.save_feeds(filtered_pth, overwrite=True)\n\n  0%|          | 0/2 [00:00&lt;?, ?it/s]Saving at /tmp/tmpf86utho5/filtered_feed/intercity_rail_gtfs_new.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]Saving at /tmp/tmpf86utho5/filtered_feed/rtm_gtfs_new.zip:   0%|          | 0/2 [00:00&lt;?, ?it/s]           Saving at /tmp/tmpf86utho5/filtered_feed/rtm_gtfs_new.zip: 100%|██████████| 2/2 [00:00&lt;00:00,  2.25it/s]Saving at /tmp/tmpf86utho5/filtered_feed/rtm_gtfs_new.zip: 100%|██████████| 2/2 [00:00&lt;00:00,  2.25it/s]\n\n\nCheck filtered file size\n\nout = subprocess.run(\n    [\"du\", \"-sh\", filtered_pth], capture_output=True, text=True)\nfiltered_size = out.stdout.strip().split(\"\\t\")[0]\nprint(f\"After filtering, feed size reduced from {size_out} to {filtered_size}\")\n\nAfter filtering, feed size reduced from 4.0M to 1.5M"
  },
  {
    "objectID": "docs/tutorials/index.html#conclusion",
    "href": "docs/tutorials/index.html#conclusion",
    "title": "GTFS",
    "section": "Conclusion",
    "text": "Conclusion\nCongratulations, you have successfully completed this tutorial. We have successfully examined the features, errors and warnings within a GTFS feed. We have also filtered the feed by bounding box and by date in order to reduce its size on disk.\nFor any problems encountered with this tutorial or the assess-gtfs package, please open an issue on our GitHub repository."
  }
]